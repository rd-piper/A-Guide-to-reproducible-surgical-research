[["index.html", "A Guide to Reproducible Research for Surgeons Welcome", " A Guide to Reproducible Research for Surgeons Dr Julian Quinn, The SERT Institute, RNSH Sydney 2020-08-04 Welcome This is the online home of A Guide to Reproducible Surgical Research. Inspired by bookdown.This book is open source. This ensures its contents are reproducible and publicly accessible for people worldwide. The online version of the book is hosted at sert.rnsh.org This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. "],["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction The articles in this collection are intended to provide guidance for less experienced researchers that are contemplating starting (or participate in) a research project. This slim volume cannot provide a detailed instruction manual for designing research projects, rather it aims to provide guidance on really important points where things often go wrong, in areas where there often is no guidance aside from experienced mentors, and on some background subjects that underlie the thinking behind research design. A better summary description of the articles would be that they provide (we hope) concise answers to questions that we at the SERT Institute were asking when we naïvely started out as researchers, as well as questions we did not ask back then but should have. This work is formed from short articles or vignettes that address a specific topic or question in a fairly condensed form. We aim to provide an informative picture for each topic so the articles average about a thousand words (the customary text equivalent of a picture) which is short enough to scan quickly. While it is chiefly aimed at surgeons, surgical students and physicians in related disciplines, the themes and practicalities of doing any kind of research are common to many disciplines, we hope it is of wider interest. One of the main aims of the RNSH SERT Institute is to provide support to surgeons undertaking continuing education, research, training and other academic activities. Surgeons are always time-poor and stressed running busy schedules but love their craft and are highly motivated to improve it, and so achieve better outcomes for their patients. It is very important to undertake high quality and robust research that demonstrate how to improve patient care, just as research done by previous generations of surgeons and medical researchers created the treatments in use now. Such research has another severely practical use: that of training young surgeons in scientific methods, since evidence-based healthcare has over a very long time proven clearly superior to evidence-free healthcare. In this small contribution to promoting such advances, we must gratefully acknowledge the great help, advice and critiques provided by staff and colleagues at the Division of Surgery and Anaesthesia in Royal North Shore Hospital, St Leonards, NSW, Australia. Julian Quinn, DPhil SERT Institute Surgical Research Officer "],["starting-and-running-a-research-project.html", "Chapter 2 Starting and running a research project 2.1 Designing research projects. 2.2 Framing a really good research question. 2.3 Writing a short research proposal 2.4 Reviewing progress of a research project 2.5 Choosing a research supervisor 2.6 Human research ethics principles – a brief introduction.", " Chapter 2 Starting and running a research project 2.1 Designing research projects. Once an exciting new research project has been envisaged and sketched out, a pause for thought is needed. Before any work is undertaken, there are important queries that need to be addressed in order to avoid serious roadblocks to progress, to help ensure the project unfolds in an orderly way, and to make sure that the goals of the study are attainable within the time allotted. How much time is available? Is there a hard deadline that cannot be changed? What are the questions that underlie the project? Can they be clearly stated? What are the ethical issues involved in pursuing the study? Will HREC and governance approval be needed? Why do you want to do the project? What is your motivation? Are you keen to do it? What resources (money, equipment and salary) will be needed to complete the project, and are they available? What skills are required? What type of statistical analysis is needed and is there likely to be enough data, i.e., is there sufficient statistical power? Who is interested in the study and its outcomes? Who is in charge of the study, who makes the key decisions? Does it involve data already generated or is will it require generation? What sort of publication is envisaged and what journal would it be published in? The first five queries relate to the feasibility of the project, so are central to the decision as to whether to proceed at all. All need very thorough consultation with a mentor (and an experienced departmental research officer) as the answers to these queries profoundly influence how a study proceeds. Some queries may have simple answers, but it always pays to be cautious in accepting that simplicity at face value. Digging a bit deeper is nearly always warranted. The most deceptively simple query is often number 2 above, relating to the research question(s) that underpin the whole study design. It is all too easy to be glib in composing such research questions, so it requires careful deconstruction. Can the question be phrased simply and precisely and do other people grasp it easily? If not, that is a danger signal that more care in framing the research question is needed. Point 8 above is also important if seeking funding support - if the research question is answered, how much would anyone care about it or find it useful? It is also an important consideration later on when persuading a begrudging journal editor to publish the work. These queries taken as a whole indicate not only the importance of mentorship and planning, but also of canvassing the views of others about a research proposal. This can be done by simply asking colleagues for comments on draft proposals, but a traditionally eye-opening approach is to present the research proposal to a group of peers. This can be done several ways, but formal presentations to a large audience are good for getting unvarnished advice from a variety of perspectives. A presentation deadline is also a useful push to get things organised. Small expert audiences are generally better for criticising project detail and for thinking in-depth about the premises of the project. 2.2 Framing a really good research question. All projects have at their heart a Question that they are designed to answer. Asking the right question is, after all, the first step to solving a problem, but it goes further than that: a good research Question clarifies a project, and helps focus the thinking and planning. Constructing a research Question sounds straightforward but is usually not simple at all and, sadly, proper deliberation of the research Question is often overlooked. This can have important consequences, because if the Question is not clear and well thought through the whole project may be on shaky ground. It should be noted as well that the research Question has to be included in some form in project reports, publications and research ethics applications, so it must be clear and concise. Another consideration at the outset is the source of the research Question – did a mentor or supervisor assign it? If so, it should not be taken for granted that it is cogent and well designed, although the chances are that it is. The mentor should discuss it in some depth, and perhaps some experienced colleagues should be consulted about it. 2.2.1 A research Question needs precision (but not too much) It is very useful to be able to state the research question succinctly in a simple sentence. There can be exceptions but if it cannot be formulated in this way then it probably needs more thought. It must sound good and make logical sense. One type of phrase to avoid would be “is important in”, which is too imprecise to help define a goal. Thus “is factor X important in process Y?” is no good. Better is something like “does factor X have a significant impact on procedure Y outcomes under condition Z?” or “among patient group X, does factor Y show a strong correlation with feature Z?” 2.2.2 A research Question should not be too long As a rough rule, it should not stretch to two full lines of standard typed text in length. However, it may have to be longer if a short preamble is needed to provide context. Or it may involve diseases with very long descriptors. The question can be split into parts and if necessary can refer to other projects, for example. Just be sure it is appropriate and makes sense. 2.2.3 A research Question should not be too vague or overarching Research projects need a reasonable timeframe and realistic expectation of resource access. Big, bold, vague concepts have no place. Feasibility is crucial. 2.2.4 A research Question is usually quite different to a seminar title Seminar titles tend to be bold and simply phrased to indicate the research area to be discussed even if that is broader than the subject of the seminar. It serves a different function to the research Question. 2.2.5 A research question should not be too parochial or small Research conclusions by their nature have to extrapolate general or big things from smaller or more restricted things. That said, a research Question that is too obscure is unlikely to interest anyone. 2.2.6 Finding causes – do not to be tempted There are many types of causes, and most diseases (and disease processes) have many causes and risk factors. Do not be tempted to state or imply that you are looking to define the cause of something. If you have a strong idea as to a putative cause, frame the question directly around that idea instead. 2.2.7 Questions point to the research aims Note that stating a research Question in the preamble of a report or funding application will naturally flow into a statement of the research aims or objectives. One question may spawn several aims, which is great as long as it all makes sense and the connections are clear. 2.2.8 And lastly Try not to be boring If the research Question is answered, will anyone care? It can be a brutal question but it can be a very useful one. Be the one to ask it, not the audience at your final presentation. 2.3 Writing a short research proposal Here, we outline some general pointers to writing a short document for seeking funding or some other type of support. 2.3.1 Decide what the proposal is about and distill it into a short title This is a useful way to refine the central idea in a proposal. It must be clear to you if it stands any hope of being understood by the reviewer or audience, and title brevity and clarity has impact. 2.3.2 Be mindful of who will review it** Any proposal must be tailored to its audience and their interests, but this is easily forgotten. The most difficult type of proposal is that intended for a lay reader. After a long training in a highly professional and technical environment it is extraordinarily difficult to write in lay language without jargon and in easily understood concepts. Practice and feedback from others is usually the only way. 2.3.3 If it is short it must be highly structured Do not waste any space with rambling text. Make sure any text is really needed, so upon reviewing it delete any text that does not enhance or further the proposal. Try starting with a set of dot points for each section then turn it into prose. Use references to minimise unnecessary methods detail. 2.3.4 Proposal overall structure This should generally resemble the following: short preamble, briefly stated aims, introduction or context to the work, methods and approaches, details of proposed work (which may be divided into sections), and outcome significance. The work detail sections should usually include a brief rationale (why you need to do something), the detail (what will be done) and expected outcomes. 2.3.5 Use diagrams, flow charts and illustrative images where possible 1 picture = 1,000 words. 2.3.6 Textual flow The language should be clear with linkage between ideas and a good style that leads gracefully and logically from one point to the next. This is a skill garnered over time through reading, writing and critiques. The style and vocabulary typical for the field should be used since otherwise becomes an irritating distraction for the reader/reviewer. Those conventions evolved for a reason. 2.3.7 Writing a short document is hard Short documents are always harder than long ones because shortage of space means a document needs to be very carefully structured, which is a surprisingly hard thing to achieve. It involves stripping the document of non-essential detail and ordering concepts to flow easily. Often a good approach is to make a solid attempt (which will be too long), then abandon it for a while, then upon return obvious cuts and unnecessary frippery is evident. If the document size goal is not reached and not yet visible, repeat the cycles of abandonment and return and eventually it will get there. 2.3.8 If there are project submission guidelines, read them carefully and adhere to them. Usually for short submissions the most important feature is length of the proposal or proposal section fields. Like all the guidelines these should be respected in every detail or its submission may not be accepted. 2.3.9 The first section or page is the most important This is where 90% of the impact is made. Any reviewer will be impressed by an opening that has a short, cogent summary of the subject, especially if it uses flowing English and links important concepts clearly to make a compelling case. Do not use grandiose styles but try to sound interesting and creative where possible, though this is often a hard ask. The ideal is to entertain or at least revive the poor tired reviewer, as their job is very tough and they may have read 50 proposals before yours. 2.3.10 Don’t be boring Break up text, make it visually interesting, and use diagrams and pictures where possible. There is nothing worse for a reviewer than pages of dense, poorly written prose. Use bold and italic fonts sparingly. Keep sentences below 3 lines. Use short paragraphs with linked ideas and link paragraphs to keep the flow. If possible, break up text with short, cogent titles that not only help comprehension but look good on the page. Sound precise and slightly fussy in detail (especially method descriptions, if there is the space) without being long-winded. 2.3.11 Don’t be repetitive If you said it before, why say again? Especially avoid saying it again with the same form of words, which always looks incompetent. There again, the major concepts and important points may have to be restated in different forms in different sections of the proposal, but vary the choice of phrasing. 2.3.12 Get someone to read your proposal critically For all but the most trivial project this is absolutely crucial. You need the objectivity that a disinterested reader can bring and you need constructive criticism even if you are already a good writer. All statements in a proposal need to be examined from a range of perspectives, flow of the arguments and the language both need to be checked. 2.3.13 Do not be precious about your work when receiving criticism. Take criticism about your writing very seriously and consider it as a gift even if it is a gift you don’t like. What is better – having flaws pointed out by a colleague or by your proposal reviewer? Always remember the point why the proposal is being written – you want the reviewer to give you something significant such as grant funding. 2.3.14 Make the expected outcomes/conclusions look different to the aims. It is so easy to make the outcomes (which should usually be placed at the end of each proposal section) look the same as the aims, which after all is logical. But don’t do it. Try putting outcomes in a wider context and make them more discursive than the Aims. The same problem can occur with aims and conclusions 2.3.15 Does the whole proposal look simple? Simple good, complicated bad. 2.4 Reviewing progress of a research project After a project has been underway for some time, it is always useful to review progress and assess whether the project is on target or flirting with disaster. Here are some points to consider. Project reviews should ideally involve a peer or mentor overview, even if this is informal, to help provide some objectivity. A general assumption can be made that original project timescales were optimistic since obstacles are harder to see at the outset. Periodic reviews will help to identify and assess those obstacles and decide how to deal with them. It is worth investing time in this and reflecting carefully on the review outcomes. Look particularly for blocks to future progress. Consider the following points: Is the project on time? How constrained is the schedule and how immutable are the deadlines? What were the expected outcomes or goals in the proposal? Are they still good goals? Were milestones (intermediate goals) set? What were they and when are they due? What obstacles have been encountered to specific goals? What skills have been gained in this project and were they gained at the expense of time? What parts of the project depend on other people, and might that be a problem later? Have all envisaged resources actually been available? If not, what effect has that had? What ethics applications are outstanding and what are their expected timelines? Has there been adequate oversight, support and supervisor feedback? In sum: Where is the project now relative to where is it supposed to be? If progress is insufficient, how can this be corrected? Does it matter? Other thoughts: How do you make sure that your self-assessment is not deluded? Are there other people, such as a supervisor, available to help with assessment? The future: If something totally unexpected happened to block one particular part of the project, would it block progress as a whole? Related to that, how linear is the project? That is, does one section of the project depend entirely on the completion of some other section(s) first? This is often a point of vulnerability. If you had to do a presentation now about the project would that scare you? Is data collection slow, such that outcomes are impossible to see until late on? What data would be easiest to collect now (or soon), and why not get it now? What data collection is guaranteed to work well and be informative? What is not? How much work and time are you putting into the project? Is it enough? Too much? Are other projects or work schedules interfering in it? What would happen if the mentor or supervisor disappeared unexpectedly for a month? 2.5 Choosing a research supervisor The project supervisor plays a central role in a successful project. This includes mentoring and guide the student, teaching good research practice, making sure that the student makes proper progress, helping resolve issues and guiding the report writing. The supervisor also has to deal with official paperwork and assessments. If that sounds like a lot, it is; he or she has many complex tasks to do for a project to be successfully completed, which is why a good choice of supervisor is so important. Indeed, having a bad supervisor is almost as disastrous as being a bad student. The supervisor’s interests needs to align with the proposed project and the interests of the student but beyond that it is not always clear how to choose a supervisor. Here are some thoughts and general principles that may help in considering potential supervisors. 2.5.1 Supervisors for degree subjects undergo University accreditation In the bad old days supervisors just had to be experts in the field, but over the decades Universities and colleges recognised the need for proper oversight and training to avoid commonly recurring problems. Thus, supervisors need appropriate higher degrees and experience, and have to undertake short training courses to become accredited. While this training is not extensive (arguably it doesn’t need to be), supervisors are well aware of standards and demands expected by the system and, more importantly, have been through it themselves as students or trainees. 2.5.2 Supervisors may come in multiples A project may have two or more supervisors, and as long as they work well together this can be a good idea, particularly if one supervisor is often absent. A second, senior supervisor often has to be approved to provide oversight when a more junior supervisor does not have a long track record in supervision, and that is always a good thing if they work together well. If they don’t it isn’t. 2.5.3 Don’t choose a very busy person as a sole supervisor One of the worst supervision problems is having a supervisor who is too occupied with other things to provide input or to read drafts in a timely manner. This can happen due to teaching, administration or surgical work overload. If this is the case it is best to have a second supervisor to help, or failing that have some other mentor who is available and willing to help. 2.5.4 Clarify how the project deadlines suit the supervisor This is particularly important for time-delimited projects where the supervisor needs to be available prior to key milestone dates. Time-delimited projects, such as Honours projects, revolve around milestones and submission deadlines so this is important. If the supervisor cannot do this well the student must act quickly to get the relevant institutional committee to initiate provisions to help with this. Degrees such as PhDs that end when a benchmark standard (rather than a deadline) is attained are less prone to such problems but even these must be carefully handled to avoid delays. 2.5.5 Be clear that the supervisor has expertise in all the areas of the project If not, make sure there is support in the areas outside the supervisor expertise, or an additional supervisor/mentor. This may include getting access to expert statistical support. 2.5.6 Work on the project aims and research questions with the supervisor These need to be very carefully thought through, but can be quite treacherous territory. It must be clear that a supervisor-to-be can do this and takes this task seriously. Make sure the aims are non-trivial, and easy to describe. Ask other (uninvolved) experts what they think about the project aims and project questions. 2.5.7 Make sure the project is feasible, and actively explore how to ensure this with the supervisor Project feasibility is usually difficult for a student to determine without the help of a mentor but is absolutely crucial. At issue is how well the work can be done with the time and resources available. Assessing that requires experience the student may not have. There are many possible issues: are the clinical data already available, with HREC approval? Is the equipment available? Funding? What could cause critical delays? The list is often long, but a good supervisor should easily deal with this. 2.5.8 Make sure the project has at least some work where results are guaranteed in the short term Having some guaranteed early results is a great way to ensure project feasibility and is an important point to ask a prospective supervisor about. Some results should be easy to obtain early on to give breathing space for training. These early results may be from a dull part of the project but it is valuable to have some progress to write about early on. The project should of course contain some more difficult aspects, which are usually the interesting bits. 2.5.9 If things are not working out Either the supervision or the project may not work out well. Either way, once a problem has become evident it is important to try and resolve this with the supervisor(s) themselves. If this cannot give resolution then getting informal advice from other mentors, tutors, colleagues and University research offices is usually the next best step. Beyond that the student needs to take things to the relevant overseeing committee, usually termed a Higher Degrees by Research (HDR) committee at the hosting institution. If the matter is serious it will be necessary to consult the formal codes of the institution to determine the procedures and actions relevant to the situation. It is important to understand that student/trainee problems are taken very seriously there are always support and advice from individuals, committees and administrative processes to provide oversight and flag where there are problems. 2.6 Human research ethics principles – a brief introduction. Human research ethics is regulated and informed by the NHMRC National Statement on Ethical conduct on Human Research, a well written but long document obtainable at the NHMRC.gov.au website. Before any work involving human participants authorisation is legally required from a local Human Research Ethics Committee (HREC). For the Royal North Shore Hospital campus this is the Northern Sydney Local Health District Research Office in the Kolling Institute (NSLHD-Research@health.nsw.gov.au), although for multi-centre studies other HRE committees may be appropriate. The formal human ethics application process (which may require an interview) for most HRECs involves submitting an application via an online system*, provision of relevant documentation and signed declarations, and a fee. The application is considered at a meeting of the full committee. Approval is rarely granted without application modifications, though these may be minor. The process is separate to gaining hospital governance approval (a.k.a. Site Specific Assessment), which is also required for research projects. Note SSA applications are reviewed by institution managers rather than by an HREC, but also need time, form filling and payment of a fee. 2.6.1 Why? Human research aims to obtain data that will improve human health or wellbeing. However, the war crimes trials at the end of the Second World War detailed how the pursuit of research could involve serious violations of ethical norms, and demonstrated that strong state regulation was essential to avoid similar horrors. Those norms were initially defined in the ten principles of the Nuremberg Code, but were later detailed in the 1964 Helsinki Declaration of the World Medical Assembly. This defined principles for judging the ethical status of a project, which have since been gradually refined and form the basis of the relevant Australian Commonwealth and State laws. 2.6.2 Human participation in research The range of activities covered by HREC regulations is wide. Observational studies, surveys, interviews, access to patient clinical or personal information (anonymised or not) and collection of human tissues all come under the HREC remit, as well as studies involving medical interventions and tests. 2.6.3 Basic principles The relationship between researchers and research participants (the general term for the subjects of the research) must reflect respect for them as human beings. In addition, the research must possess merit and integrity, and display beneficence (i.e., care for participant welfare), protection from harm and consideration of societal and cultural implications of the research. The central value is that of respect, based in recognition that all human beings have intrinsic worth so cannot be viewed merely as an instrument of the research. It also demands that all individuals be regarded as having equal worth. The principle of respect not only implies that studies be designed to minimise risk of harm or discomfort, but also that where there is no benefit to a participant the risk of harm should be particularly low. These principles lead to the very heart of human research ethics – the requirement for consent by any research participant. This consent must be voluntary and properly informed by adequate understanding of the project. This requires engagement from the researcher to ensure consent is properly obtained, signed off and notified. Consent can be withdrawn by a participant at any point and for any reason, or none. Where a participant cannot give consent (e.g., due to cognitive impairment) then an advocate needs to be involved to protect the participant interests. If data is aggregated and anonymised, cannot harm participants (even if the data is misplaced) and individual consent burdensome to obtain from all participants then an application to the HRE committee can be made to waïve the need for consent (see below). 2.6.4 Harm and risk of harm The notion of harm is a simple one to understand although, for HREC assessment, its nature and severity are important parameters. It is important to note that firmly within the definition of harm (albeit at the low end of the scale) are discomfort, inconvenience and breach of privacy. Discomfort includes minor effects of blood sampling but also medication side effects, taking blood pressure and any anxiety induced by interaction with a medical researcher. Inconvenience refers to the time taken to participate in the research, even if it is a survey. Breach of privacy includes release (accidental or not) of personal information about a participant. An important concept is that of risk of harm and it may be just as important to minimise this as to minimise actual harm. A procedure involving only inconvenience is viewed very differently if it involves even a small risk of injury. Thus, risk needs to be assessed as well as harm. A risk is a potential for harm (including discomfort or inconvenience) and involves an assessment of both harm severity and harm exposure. The researcher(s) and the HREC thus need to identify any risks, gauge their probability and severity, assess how much they can be minimised, determining whether potential benefits of the research to justify the risk, and determine how the risk exposure can be managed. 2.6.5 The role of the HREC Aside from fulfilling a formal legal oversight role, an HREC makes judgements on whether risks of a proposed research project are justified by potential benefits, including the participants’ perceptions of those risks and benefits, determine that an indemnity system exists to compensate for any harm suffered and manage conflict of interest among the researchers. An HREC that is appointed under NHMRC guidelines includes an overseeing chairperson, two laypeople (male and female) with no research affiliation, two experienced medical researchers, a lawyer where possible, a person with a community pastoral care role, and a person with experience in medical care or counselling. 2.6.6 Negligible and low risk projects Low risk implies a risk only of discomfort, and negligible risk implies no harm more than inconvenience. Many data analysis projects that study aggregated data from past patients would fall under such a category if the data in anonymised. This can be achieved in databases such as REDCap, although there is as yet no legal definition of “anonymised” in Australia. It is possible to apply to an HREC to have a waiver issued for the need to have formal consent from the participants where this is impractical and unnecessary given the low/negligible risk of harm. \\(\\ast\\) Note - For many NSW Ethics committee submission (including Kolling Institute/RNSH) is now done via the Research Ethics Governance Information System (REGIS) which is entirely online. For some authorities (e.g., North Shore Private Hospital) this is HRE Application System (HREAS) which includes template forms. "],["statistical-issues-in-research.html", "Chapter 3 Statistical issues in research 3.1 Statistical analysis of data – a random sample of thoughts 3.2 Power calculations and why they are needed 3.3 Systematic Reviews – A Short General Introduction 3.4 Regression to the mean – a bewildering effect of random variation. 3.5 Making multiple comparisons and ANOVA testing", " Chapter 3 Statistical issues in research 3.1 Statistical analysis of data – a random sample of thoughts Statistical analysis is an enormous subject which cannot be seriously addressed in a short article, but below are some brief points to consider when designing, executing and analysing a study. 3.1.1 Statistical thinking needs to be done before the study begins Researchers often think of data as needing statistical analysis after it has been collected, but statistical modelling should be used from the earliest stages in the design of the study. That is, the study should be designed at the outset to give the best chance of generating informative data. Usually in medical projects the most important consideration is statistical power, summarised below. What is your level of statistical training? Any researcher that has a good grasp of normal distributions, probability, p-values, t-tests, ANOVA, chi-square tests and non-parametric testing has a good enough understanding to run simple analyses and should be at a level to discuss analyses and planning with a data manager or other statistically trained person. A researcher without those skills then needs to tread very carefully, and will need an expert mentor to consider and explain this aspect of the project, and provide some basic training. A researcher with relatively high skills so that, say Cox proportional hazards model, Kolmogorov-Smirnov tests, Bayes’ theorem and Kaplan-Meier curves hold no fears, then that researcher is better equipped. Even so it is always worthwhile to take time to discuss with peers and mentors about the methods and outcomes of the project statistical analysis. Statistical significance does not always mean medical significance If patient weight is monitored as part of a study of a weight reduction therapy and that therapy causes a statistically significant decrease of 10g, no one would care. Large datasets in particular can sometimes give highly significant results when a statistical test is applied but the observations may not be meaningful if they only show up tiny changes that implying the intervention has negligible, if measurable, effects. Confidence in significant differences When applying a t-test to compare the effects of a surgical intervention and sham intervention on a patient interleukin-101 (IL-101) levels, there are three types of outcomes possible. Firstly, treatment may result in a significant increase in IL-101, i.e., the mean level of the treated group is significantly higher than that of the sham group. Secondly, there could be a significant decrease. The third possibility is that no significant difference in IL-101 seen between surgical and sham groups. A little more formally, we would say that the mean IL-101 levels seen in the treatment group lies inside a grey zone, the confidence interval, that lies around the mean of the sham operated group. If our treatment group data mean ends up in that zone then the difference was not statistically significant. That means either the intervention had no effect (so the apparent difference seen is only due to random variation in the data) or the effects of the surgery was just too small to see because it is swamped by natural variation (a.k.a. noise) in the data. The latter means the power or ability of the study to see an effect may be insufficient, just as a magnifying glass cannot help you see a bacterium. We cannot distinguish lack of effect from lack of study power; so if we can’t see bacteria, either they are not there or the magnifying glass is no good. We cannot be sure until we buy a microscope. So a statistically significant result proves an effect exists? Evidence for an effect yes, absolute proof no. When the surgery does result in a significantly changed IL-101 level it means there is a low probability of that the data (or data more extreme) could be observed due to random chance. How low the probability is depends on the study, but is often 0.05 or 0.01. Statistical inference can be a slippery thing; always involving layers of interpretation and depends critically on the right statistical model being used. With great power comes great reproducibility From the above, it follows we can only show a significant difference if the surgery effect is large enough that it is not overwhelmed by the natural random variation in the data. One way to reduce such random data variation is to increase the number of patients measured. If we do that then the surgery effect measurements may escape the grey zone, so that an effect (if it one really exists) can be seen. This increase in number of measurements causes an increasing in the ‘power’ of the experiment. In effect this is the power to spot a small but true difference between groups, though that is not its formal definition. Power can be estimated, and used to determine the number of patient measurements we need to make. It is crucial to know this for the study design, so that power is high enough to give a good chance of seeing a real and reproducible difference. Otherwise we are wasting our time and our patients’ time on the study, which has ethical and cost implications The hidden horrors of multiple testing When comparing mean values of two groups (say, placebo and a drug treatment) we may perform a significance test, such as a t-test. This give us a p-value representing the probability that difference between the groups (or a bigger difference) is due to random chance. We conventionally accept a p-value below 0.05 as significant though this is not very stringent, and 0.01 is better. However, if we make two comparisons at the same time (e.g., comparing placebo with drug A and with drug B) and if both comparisons give a p-value a smidge below 0.05 then the chance that one of the two results is due to random chance is almost 10% (p=0.0975), which is no good at all. This is because multiple comparisons mean that p-values must be combined and adjusted so that we are not fooled by a false positive result. One very common method for this is the Bonferroni adjustment. In sum, multiple comparisons give a very different outcome to single comparison. It is like flipping a coin – chance of getting a head is 50% with one flip once but flipping 20 times makes it certain. Torturing the data till it confesses what you want With large datasets it is possible to perform significance testing on many parameters, and if nothing looks good you may look for significance in a subset of the data. For example, if the test of a drug finds no effect then you might notice that if you exclude patients over 80 year old it looks more promising; this may reduce the p-value to below 0.05. This procedure is bad, it is called data torture and it is horrible, but surprisingly popular. A hypothesis test must be designed before the data is obtained, not after the researcher had a chance to squint at it. That said, such post hoc subset analyses may suggest a useful idea for a new hypothesis for testing in later studies, which is fine. A good source of information about these and related statistical sins is found in the short classic How to Lie with Statistics by Darrell Huff (Norton &amp; Co, 1954) if you can locate a copy. But is it normal? Most statistical tests (e.g., t-tests) assume that the data follows a normal distribution, so when it is plotted out the data has the distribution of a bell curve. This can be tested mathematically, which is less trouble than plots and more objective (after all, how bell-like is your curve?) but it if turns out your data does not follow a normal distribution then t-tests will tell you lies. There are ways around this problem, the most straightforward of which is to use a non-parametric statistical test that does not assume normal distribution of data. Thus, instead of a t-test use a Mann-Whitney test. Bear in mind, however, the power of these tests is less, so they may return a false negative result. Statistics: not the only way. Statistical analysis is not the only way to interrogate your data. There is an emerging field of machine learning which can spot patterns in the data when statistical analysis cannot. This can be worth considering, but it is not for the faint hearted and is generally only useful for very large datasets. Indeed, it often gives outcomes that are hypothesis-generating rather than analytical in nature. 3.2 Power calculations and why they are needed When designing a clinical study we must decide how many study subjects will be included. This is required for planning, budgeting and ethical approval. Determining the minimum number of individuals to enrol in a study requires a statistical power calculation, which is not difficult in practice but needs an understanding of some statistical theory. Here, we discuss the ideas that underpin power calculations. A hypothetical clinical trial Consider first an imaginary study we have completed called the DOSH trial which compared a treatment group to a control (placebo) group. The DOSH trial investigated whether a drug treatment makes people richer, measured by bank balance magnitude, BB. The trial estimated whether an effect of the drug on wealth, BB, exists and the size of the treatment effect is, i.e., how much BB was increased after treatment. Note that the larger the treatment effect is then the easier it is to see (and to demonstrate) that it exists using statistical testing. The importance of being significant Demonstrating that a drug effect on BB ‘exists’ means that we can show that the differences seen between the treatment and control group wealth are unlikely to be due to random variation or chance alone. This is decided is based on statistical hypothesis testing, and for this the DOSH trial used a t-test analysis of the mean BB levels of in the two groups, which takes into account the natural random variability seen in wealth levels. Crunching DOSH trial numbers found that the chance of the observed increase in BB in the drug treated group occurring purely by chance was 4.5%. This was regarded as statistically significant as it was less than the selected 5% significance threshold. Thus, we consider that there is a difference between the two groups that is unlikely to be due to random chance variations. We therefore infer that the drug really did increase bank balance levels, and we can estimate on average how much more money people had with the treatment. Job done. Power and what it means All of the above relates to a study that is already finished, so now suppose that we need to do another imaginary study called MoOLA on different population. How many individuals do we need to recruit to MoOLA so that we will have a 80% chance of seeing a similarly significant result to DOSH? This question relates to the power of the new study. If there are too few people recruited and it will be difficult to see a statistically significant difference of 5%. In this case the study is underpowered so you are wasting everyone’s time as an effect will not be detected even if it is there. The ethics committee will not take kindly to it either. If there is a massive abundance of subjects investigated the study may be overpowered, which is far less of a worry (and rarely happens), but is also wasting resources and the ethics committee will again not be pleased. How to estimate study power To work out the number of patients needed to power the MoOLA study to see a statistically significant outcome we need some prior information about the key parameter. Since we have the data from the earlier DOSH study we can use that. We first decide: How big is the effect size we want to detect in MoOLA Consult the data from DOSH to find how much BB varies by We choose a significance threshold (here 5%) We choose a tolerable false positive rate, usually 80%. This is enough to calculate n, the number of subjects needed. To do this with the information above if we define Diff as the previously observed mean difference between treated and control, SD as the observed standard deviation and SES the standardised effect size then: \\(SES = Diff/SD\\) and \\(n = 16/(SES)^2\\) The need for prior data Notice that for MoOLA we had prior data (DOSH) to help us with the power estimate but it is possible that no similar study of a lucregenic drug has been done before. There again, the prior data only has to provide an estimate, so may be from a different but related treatment; some thought needs to go into what is appropriate. Small (i.e., underpowered) pilot studies might be alright for this. Also note that the power or n estimate only relates to measuring parameter M; if other parameters are of equal interest power and n may need to be adjusted accordingly. Significance thresholds and the pain they cause It is important to note that the 5% significance threshold used above is both arbitrary and low. The assumption that random chance effects do not exist if their probability is below 1 in 20 is commonly made, but not very robust. The sad truth is that many studies give conclusions that are weak because of this, but power (and hence significance) is dependent upon the number of individuals studied (n) and in reality there may just not be enough study subjects to go around. Note that we have to be alert to the possibility that while an effect on BB may not explained by random chance, it may not be due to the treatment either but rather some sort of bias in the study design. Other types of studies Note that the above description relates to a small clinical trial, but the same or similar statistical approach may be used to estimate power in other types of studies, such as observational and time series data or animal studies, though the power calculation method may differ accordingly. 3.3 Systematic Reviews – A Short General Introduction Clinicians need to know whether a treatment may be effective for their patient or, indeed, if it works at all. Published clinical studies are the main source of authoritative and objective information but there are problems in simply accepting these at face value: studies vary enormously in size and quality and may contain biases (i.e., systematic errors) that undermine their conclusions. To make matters worse, there is the problem of publication bias, whereby not all studies are published. Thus, for example, exciting first data on an innovative therapy may be published with fanfare, while later boring studies showing that the therapy is useless struggle to be published at all. As a result, unsuspecting clinicians performing literature searches see only the positive results and so can be badly misled. These problems can, at least in principle, be dealt with by systematic reviews. Unsystematic reviews A ‘literature review’ conventionally refers to an article that paints a detailed picture of the general current state of knowledge and thinking in a subject or field. Such a review is always supported by an accompanying extensive list of cited papers, bibliographies that are themselves useful resources. Such reviewing has a long and honourable history, but in recent years as emerged the more specialised and focussed type of article, the systematic review; the older type of review is usually referred to as a “narrative” review to contrast it. What are they for? A systematic review seeks provide a direct answer to a focussed clinical question, and assesses the strength of evidence that supports that answer. The question addressed may be simple but it is narrow, such as whether a specific treatment is effective for a condition in a particular category of patient. Secondary questions, such as optimal dose or the frequency of complications may also be addressed. Systematic reviews promote evidence-based medicine as championed by the Cochrane Organisation, a resource supported by medical institutions worldwide, and are regarded as a very high level of clinical evidence. What is systematic about it? Scientific endeavours are all systematic in some sense, but here it means the whole review process itself is systematic, not just its methods and analyses. It follows a set of prescribed and standardised procedures. For example, a systematic review performs meticulous and exhaustive searches for all accessible clinical studies that address the question in hand, and details of that search process are declared. This includes studies found outside of standard journals or in languages other than English; this aims to overcome publication bias. How is a systematic review performed? That subject takes up entire books, with many aspects still quarrelled over. However, the general conduct of a gold standard systematic review is widely agreed. A systematic review is performed using a transparent, orderly process to identify and assess relevant published studies. It weighs the evidence from those studies to reach a considered statement on the subject of enquiry. The systematic reviewing protocol is first designed, registered and published (accessibly) so that the review can later be seen to conform to the original intent, removing temptations to ‘improve’ it later. All pertinent studies are then located, and a pair of researchers filter out those insufficiently relevant or informative; this filtering is itself described in the review manuscript. The selected studies then undergo evaluation of their scope, quality, biases, conclusions and soundness of their conclusions. What is done with this information? The outcomes and information from the reviewed studies are synthesised to reach a nuanced conclusion for which the studies provide support. There is an assessment as to whether the evidence is strong enough to be acted upon in the clinic, whether further studies are desirable and whether further issues are raised, such as the consistency of the therapy outcomes. Is all that effort really needed? The reviewing process is time consuming but is needed because the biases and problems quality affecting the studies must be exposed to daylight and critically evaluated. This facilitates good integration of information to enable rational clinical decisions. Developing a systematic review uses many tiresome and tedious techniques but demonstrably and drastically reduce bias. It is part of human psychology that biases are underestimated and ignored, and a key objective of evidence-based methodology to overcome this dangerous tendency, and such efforts are rarely glamorous. There is good evidence, for example, that studies that do not have fully blinded patient allocation to treatment and placebo arms display systematic bias and error. Note also that a systematic review can be regularly updated (i.e., repeated) as more studies are performed, leading eventually to consensus on best practices. What types of studies are included in the systematic review? All relevant published data and grey literature, suitably filtered. ‘Grey’ literature refers to studies not formally published in conventional journals, such as published abstracts and conference presentations, non-peer-reviewed manuscripts (e.g., bioRrxiv) and studies not published in English. It is challenging to find and interpret such studies but it is a vital task. What about meta-analyses? A meta-analysis goes a step further than a systematic review as it takes published data and aggregates and appraises it with a number of statistical tools to reach conclusions based on quantitative analysis. This is a powerful method that can result in strong conclusions if the studies under scrutiny are under- or poorly-powered small studies, so can provide stronger evidence than the individual studies alone as long as biases are recognised and dealt with. What happens if the studies that the systematic review reviews are no good? Aggregation of bad data cannot magically produce good data, but part of the systematic process is to weigh the quality of the studies. Good data with low bias from large studies contributes more to review conclusions than data from a poorly executed and wobbly study with few participants. However, aggregating of weak studies can provide useful data for meta-analysis, so collectively provide stronger evidence that the individual weak studies can. How are the biases and other flaws in studies assessed? The standardised methods used reduce bias cannot easily be summarised here, but common approaches include standard checklists (e.g., to assess the quality of randomisation and blinding) or quantitative measures such as funnel plots that assess publication bias. Such particular methods are selected beforehand then used rigorously and with great care. In sum, a well performed systematic review is a crucial and high quality contribution to evidence based healthcare. 3.4 Regression to the mean – a bewildering effect of random variation. Randomness can play tricks on us and behave in some odd ways. A good example is the phenomenon of ‘regression towards the mean’, but also called ‘reversion to the mean’ which is a little easier to grasp as a term. This phenomenon is important to be aware of when designing clinical trials, and it is commonly encountered so it is useful to be able to spot it and avoid being fooled. To paraphrase its statistical description, an extreme event will nearly always be followed by a less extreme event. While this bland description captures its essence, it does not portray very well how such a malicious trap lurks in the shadows. Terrible darts players Imagine that you are a very bad darts player, so can land a dart on the board, but exactly where it lands is pretty random. As a result the laws of random chance best describe the score you obtain from throwing three darts. Imagine also that several friends, who are just as hopeless, join you to play a few rounds. On the sixth round one friend scores extremely well, but you do badly. The next round your friend, fired up but still hopeless, scores only a little better than average, as do you. On the seventeenth round you have a stunning win and a very high score. However, your triumph crumbles the next round, so you lose badly and slink miserably off to the bar. The above scenario is familiar and easy to understand. It is plain why one or two high scores happened and why they are not repeated – they were just flukes. Over the long term if the score of each player is added up they will all tend toward same number, which is the average (or mean) of the group, however over the shorter period such flukes will be apparent. Freakishly low scores of course also happen, again followed by scores closer to the average. There is no formal cause for your unusual high score – it was chance, and you had little or nothing to do with it. Note that here we assume that your skill levels in darts do not go up, though of course with time and persistence it will, and the scores less random. Punishment, reward and intolerant teachers To take the example a little further, imagine you have acquired a darts teacher who is completely ineffective but unaware of it. He yells at those students who score very badly and praises those who score really well. The laggards immediately improve, but the high achievers go backwards. A logical conclusion seems to be that praise doesn’t work and that yelling at bad players does, in defiance, it should be noted, of the insights of psychology. However, exactly the same pattern of improvement and worsening in your darts matches will be seen even when the teacher is not around to praise or punish. This is easy to explain if reversion to the mean is seen for what it is, but we seem almost hardwired to see things as the teacher does. Invisible randomness The problem always with randomness (i.e., non-systematic variation around the mean) is we often are blind to the magnitude of its effects and the role they play. We always look for explanations that involve simple causes, especially human agency. So the good scores we get are ascribed to positive thinking, our hard effort, or our rabbit foot, but we then forgot to keep thinking positively or took our eye off the ball, or the foot. The human brain is so good at spotting patterns it has no problem spotting patterns that do not exist, indeed many brains resist the very notion that random chance exists. Temporary successes in many fields of endeavour, even in research (who knows) can be susceptible to the warm embrace of good fortune followed by the cold shower of reversion to the mean. Thus prizes can be awarded to the outstanding, who then go on to disappoint. This is not due to a jinx but our underestimation of how large a part randomness plays in performance. This happens with clinical data as well. An aside: Francis Galton Regression to the mean was discovered and described by Francis Galton in the 19th century. As part of his otherwise unfortunate dedication to eugenics he made many measurements of height of parents and their children, noting that child heights usually lay between the mean of their parents and the population height mean. By mathematically describing these observations, he stumbled upon the ideas of simple regression that now play a fundamental part of statistical analysis. Influences on clinical trial design It is now widely understood that when setting up a randomised clinical trial the best design is (as the name suggests) to randomise the subjects at the outset, and to do so rigorously. This does make intuitive sense since it means the control and treatment group will be equivalent. If, however, we consider what might happen if this is not done in a disease treatment trial – if at the start the treatment group actually had worse symptoms than the control group, any apparent improvement may just be reversion to the mean and not a treatment effect. Random blind allocation minimises this, so is crucial. Effects of reversion to the mean can be compounded by putting study subjects into groups based on initial (baseline) parameters. So, if patients are allocated to a study based on one measurement being above a threshold, some may be false positives at the start because they were by chance higher than usual for them. This can be avoided using allocation based on more than one parameter to reduce effects of reversion to the mean. What to do Reversion to the mean is usually tackled by using careful protocol strategies to avoid it, some as outlined above. This is why the many time consuming tasks of double-blind patient allocation to treatment/placebo, pre-registration of trial protocols and other irksome duties need committed and careful adherence. Statistical analysis and estimation techniques exist to prevent problems around reversion to the mean; one useful and readable resource is noted below. Further entertainment There is much literature on this subject much of which is highly readable, in particular from giants in the field Daniel Kahneman and Amos Tversky, and Dan Ariely. Ref- Barnett A, Van Der Pols J, Dobson A, (2005) Regression to the mean: what it is and how to deal with it, International Journal of Epidemiology p215-220 3.5 Making multiple comparisons and ANOVA testing One of the foundations upon which a medical study rests is the statistical testing of its data. This can unfortunately be undermined by a common problem seen even in highly respectable peer-reviewed literature. This problem arises from making multiple comparisons in the data. It is a reason why so many studies are hard or impossible to reproduce. Since a study that cannot be reproduced is a waste of time it is essential for researchers understand this issue, since it has a relatively easy to fix. Making single comparisons Statistical tests can assess whether or not a pattern in the data simply reflects a pattern of random variations. Working on random numbers is of no interest to anyone, so an objective methods are employed to spot random patterns since the human mind is very bad at this and is easily fooled. A commonly used test is Student’s t-test for comparing data from two categorical variables. Thus, to see the effects of a drug on a patient parameter (such as their hematocrit), two groups are set up: patients taking the drug (the treatment group) and patients not taking it (the placebo group). Measurements of hematocrit are made from both groups of patients. The question is whether the drug affects the parameter of interest, here the hematocrit: formally, the question is whether the group receiving the treatment has an increased or decreased average (mean) hematocrit compared to that of the placebo group. Since random data fluctuations from a variety of sources will also cause some variation in the group means, so we want to know a change in mean hematocrit is not explained by such random fluctuations. The t-test can do this job, but it does not return a yes/no answer but a p-value, which we have to interpret. P-values The t-test p-value is an estimate of how likely the difference between the means of treatment and placebo groups (or a greater difference) is due to random variation. A p-value less than 5% is commonly used to establish a true non-random drug effect, designated as ‘statistically significant’. Note that a p-value above 5% does not prove that the drug has no effect, it simply means that we have no evidence for any effect. With this caveat, a p-value of 5% represents a 1 in 20 chance that this conclusion is wrong, i.e., it was random after all. This is the source of the problem. Multiple tests can spoil everything The t-test and the p-values it yields are widely understood, but often we want to test more than one parameter. Suppose 20 parameters are tested in patients taking that drug and that t-tests are performed on all and them and, furthermore, all those tests give a p-value of 5%. Having 20 comparisons each of which has a 1 in 20 chance of being wrong suggests that something will be wrong. In fact the chances they are all non-random true effects being observed is only about 1 in 3, and it is not at all clear which of those parameter are giving a false positive. Ronald Fisher’s potatoes Fisher was one of the founders of statistical science and invented many of its core concepts such as p-values. In the early 1920s he had data on the yield of 12 different varieties of potatoes and needed to find which was the most productive crop. For this he used his ANOVA (or analysis of variance test), model. The mean and variance of the measurements of potato yield for each variety was calculated and the ANOVA test determined whether all the means were the same or if there was some difference. Thus, ANOVA compared how the individual mean differed from the overall mean of data all the varieties pooled together; the degree of variation between groups and within groups was also compared. The potato data analysed this way indicated there were differences between the fertilisers. However, the test did not reveal which gave varieties were best. This lack of information on individual potato types is a feature of an omnibus test that only gives useful general information about a dataset. This is like a biscuit jar in a share house found unusually empty, indicating that biscuit consumption has suddenly increased without identifying the culprit. However, it is best to determine that the biscuit jar really is low before leveling accusations. In the same way the ANOVA indicates that there is some statistical signal which can be followed up. Threshold correction To identify which potato is best, a post hoc test is need; the test is called this as it is done after the ANOVA screen. There are various approaches used, and some disagreement as to the most appropriate (it depends on the dataset) but a common approach is to adjust the p-value threshold to compensate for multiple testing and reduce the number of false positives. The False Discovery Rate is an algorithmic method used for large datasets. Also common is use of pairwise t-tests used to compare each pair of means (here, every two sets of potato variety) with a Bonferoni correction to the p-value threshold. In this case the threshold (here, 5%) is divided by the number of tests done and that adjusted p-value used to determine significance. Other tests exist (termed post hoc tests) , such as Tukey’s, which is more conservative, i.e., harder to obtain a significant result. 1-way and 2-way ANOVA Fisher’s fun with potatoes did not end with potato varieties since there are different types of fertilisers used with the potatoes, and the varieties varied in their response to the fertilisers. This provides an extra dimension (or category) to the data results in a two-way comparison, since the potato yield can vary due both to potato type and fertiliser. This cannot be done with the simple ANOVA as described above and requires a 2-way ANOVA test. Similarly in clinical data there may be both treatment and patient sex to take into account because there may be a difference in treatment response between the two sexes. 2-way is more work to calculate than 1-way ANOVA (horrifyingly so in Fisher’s day) but when using computer software the work is only slightly more. Not using ANOVA The main assumption underlying ANOVA is that like t-test there is an assumption that the data is normally distributed. If this is not true, a test such as Kruskal-Wallis with paired Mann-Whitney tests can be used. These tests data ranks rather than the data itself. Which test to use may depend on the software available but it would be wise to get some advice on this. There are other approaches to examining multiple comparisons, such as methods based on Bayesian statistics, but this is a large subject in itself. "],["research-gone-bad.html", "Chapter 4 Research gone bad 4.1 Research integrity 4.2 Narratives : necessary but dangerous. 4.3 Psychological biases in scientific research 4.4 The replication crisis in medical research 4.5 Survivorship bias 4.6 Parkinson’s Laws and related project planning pitfalls for researchers", " Chapter 4 Research gone bad 4.1 Research integrity Integrity : the quality of being honest and having strong moral principles [Oxford English Dictionary] There are strong motivations for physician-scientists to publish research papers, including recognition and career advancement, gaining a qualification or consideration for a good post. It is obviously not good to view a piece of work as just another publication on the CV, since it should have its own justification. Nevertheless, inappropriate motivations to publish cannot be wished away, and it is important to recognise that it can lead to actions that can violate the integrity of the work. In most contexts it is useful to think of research integrity as broadly equivalent to ‘honesty’, but in practice research integrity goes well beyond that. Research integrity carries a requirement to ensure there is no deception, intentional or inadvertent, and also that there is no other unethical behaviour such as cruelty to animals or lack of care for patient personal privacy or agency. To ensure high integrity it is commonly agreed that it is not enough to rely too much on a person’s intent or goodwill (though that is important), but to have procedures and cultural norms that reliably detect and avoid undesirable behaviour. When we think of deception we think of dishonesty or fraud, but the easiest person to deceive is ourselves; the scientific method properly applied should minimise this so we do not credulously pass on a falsehood. Another example is that in human ethics there are in place processes and procedures that oblige us consider deeply the risks we may inadvertently expose a patient to. We need to use such methods and if we do not, we are not displaying proper integrity even if we do not mean to be bad. Integrity also implies a steadfast attachment to a set of ethical principles. This carries with it in medical research a severely practical consequence, the obligation to apply to an ethics committee for permission to pursue a study where it concerns a human or animal subject. This partly converts an exercise in ethical behaviour into form filling, which is not fun, but as noted above it has the positive effect of pushing the applicant to scrutinise carefully important aspects of their work and to use standardised methods that are regarded as ethically sound. It is an awkward fact about research ethics that it involves reducing risks that are not at all obvious or central to research, such as risks around insecure storage of personal electronic medical data. 4.1.1 The importance of not making things up Presenting or publishing data that has not been honestly generated or that has been made up for clearly fraudulent purposes constitutes serious research misconduct. Science, in theory, should not need policing since a finding that is wrong cannot be replicated so does not find its way into the accepted corpus. In practice there are usually severe consequences of fraudulent data, including the waste of time and effort to replicate it and the danger that clinical treatments based on fraudulent data pose to human health. Faked data usually involves the misuse of research funds that supported the researcher, so it is also a civil legal matter and may be a criminal matter. However, data fraud invokes such visceral dismay amongst scientists and physicians mainly because it betrays the implicit pact to trust each other to be always open, honest and receptive to criticism. Scientific institutions thus have strong ethical rules that render this severe breach of trust an employment-terminating matter at the very least. Such a rupture in this system of trust causes reputational damage to all involved, and betrays the trust of non-scientist taxpayers and charity-funders in scientific institutions. 4.1.2 The importance of not making things up even a little bit While fudging or copying a small inconsequential figure or numerical data may not seem important, it really is. No medical or scientific institution can tolerate even the suspicion of dishonesty, so it is a central part of the culture of science that we learn to police ourselves in minor things, and we cannot function as scientists if we allow ourselves to lapse in this regard. This is not because these minor things are not minor (they may well be), rather it is because it is a failure of self-policing, as well as a failure to adhere to an ethic that so crucial to the research endeavour. In clinical research this can even include accepting incomplete datasets as if they were complete, or knowingly analysing datasets that may not have been rigorously or prospectively collected as described 4.1.3 What if it is someone else? A really thorny problem arises if we become aware that someone else may be lacking in research integrity. This needs to be tackled with sensitivity as it would be in any other walk of life, as suspicions can be wrong. It may be best to discuss misgivings with the person involved to ensure any problem is fixed and not repeated. Preventing someone from acting improperly in a minor matter is doing them a big favour if it prevents the consequences of a worse infraction (e.g., publishing fraudulent data) later on. It is certainly advisable, and it may be mandated, to consult with a mentor or an official with responsibility for research integrity. The path taken is very context dependent and depends on the guidelines of the institution (they all have them) so it is best to consult these. 4.1.4 Human research ethics committees No committee can oversee clinical activities in detail, so various approaches have been developed to deal with these issues. From a researcher perspective, it broadly means training and ethics application forms. Most issues around research ethics arise from a lack of awareness of the researcher as to what is expected and is permissible. Training, form completion and ethics committee engagement can address these issues effectively, but they also enforce openness about researcher intentions through the requirement to document them beforehand. A perennial issue is that the number of ethical concerns can only rise over time as new problems and procedures appear, so the amount of work involved in ethics committee applications also rises over time, despite occasional efforts to streamline processes. 4.1.5 Study design Less often considered under the heading of research integrity is the requirement for good study design. A poorly designed, underpowered and badly analysed study runs a severe risk of generating misleading data, due to biases and random chance. This must be avoided. There is an aspect of data analysis formally (and rather curiously) named “Vibration of Effects” which is the ability of a dataset to be analysed by many different statistical tests to give a range of different outcomes, meaning they lack robustness. This needs serious thought. 4.1.6 Conflicts of interest This is an important issue defined as researchers having some financial or other strong interest in the outcome of the work. This can at the very least lead to biases in data interpretation. Where these conflicts cannot be avoided the main recourses are to minimise them where possible, and to declare them openly and let others decide if this irredeemably biases the study conclusions. 4.2 Narratives : necessary but dangerous. An often heard piece of good advice to a new researcher attempting scientific prose is to “tell a Story”. This Story is sometimes referred to as a Take-Home Message, the thing that (it is implied) the reader or audience should remember long after the bothersome details have faded from memory. We can think about the Story in two different ways. In the first way, a Story highlights a cogent point or set of points, forming a focus of the work that points the reader towards a clear and easily understood conclusion. This makes the task of writing much simpler. As well as a focus and a structure, the Story can give the writing a certain vigour and coherence and, if done well, makes the writing compelling and persuasive. It is worth noting that undergraduate students in particular often write up their research projects as a catalogue of apparently unlinked data and arguments that inspire little engagement or insight and with no obvious rationale. This is a consequence of lacking a well thought out Story. The data and analyses may be central to reporting a study, but the Story will link these disparate elements to give them a form needed for proper communication and understanding. Note that it is common to summarise or declare the Story in the title of the document, which is why it can be helpful to work out a draft title to help the writing process. The second way to think of the Story is as a form of information compression. The human mind takes in information very efficiently in narrative form and as it allows us mentally to fill in implied (but not supplied) information. Consider two versions of a statement* : “The queen died and then the king died”, and “The queen died and then the king died of grief”. Only two words different, but while the first is a simple statement of a sequence of events without even a sure link between the affected individuals (apart from social rank), the second version is richer and contains hints of a plot with personal motivation, causation and personal relationships. All from two words. This is the power that narrative has, and why it is so important to scientific writing. It compresses information by drawing on knowledge the reader already possesses (we know many implications of ‘grief’ and ‘dying of grief’) as well as a store of stories we inherit from our culture(s) with its many stories of royalty, grieving and dying that we have imbibed. Narratives are a natural and powerful way to learn, and seem to be a central and universal feature of human psychology. Their importance is evident in literature, poetry, politics, advertising and many other fields. But there is a dark side that lurks in a narrative: the Narrative Fallacy. Nature, by and large, does not have narratives; they exist only in our head. A good narrative can impel people to think that a conclusion is logical and perhaps inevitable: if A and B followed by C then D, then we all know that E happens next. The conclusion of E may not be wrong, but it may not be as certain as it seems. This is a type of cognitive bias or fallacy – that is, it is true if the Story sounds good. Such biases can fool us badly but, happily, in the scientific method we have thinking tools that make us question and check and with luck overcome the effects of this and other biases. To summarise, narratives are a very useful, a superb communication method, but be careful not to take it too seriously. based on an oft-quoted example from E.M. Forster Aspects of the Novel, 1927. 4.3 Psychological biases in scientific research People do not process data as computers do; that is, as a sequence of logical processes that follow instructions to give infallibly correct answers. That much is evident to anyone using a computer, but the differences are very profound. With careful effort, humans are capable of strictly logical thought, but everyone knows, that everyone else is not very logical most of the time. It is easy to demonstrate that the human mind uses shortcuts or approximations without much awareness of doing it. Indeed, driving a car (for example) would be impossible if we had to consciously think of every action. We catch a ball by rapid reflex, quickly decide where to lunch in a city full of cafes, cross a street unhurt and recognise a friend in a crowd of strangers. These and a million other amazing things we do with those rapid approximations (or heuristics) that work most of the time, good enough for hunting wildebeest in the savannah and not bad in a modern city. They also enable strategies to make decisions under uncertainty, such as choosing birthday presents for teenage nieces, where logic is not enough. These unconscious shortcuts and approximations lead to a curious shadowy side of the human mind: the cognitive biases. These are the systematic thinking errors we make. They are of crucial importance in virtually every field of human endeavour, but especially in scientific research. The scientific method is, in large part, a way to overcome errors these biases cause. There are now a very large number of cognitive biases that are well documented and defined; below are a biased sample of the more interesting ones. 4.3.1 Confirmation bias All people have a strong tendency to overestimate the importance of information that support their existing beliefs and underestimate information that does not. 4.3.2 Hindsight bias or outcome bias Things that happened seem virtually inevitable in retrospect, while things that did not happen were bound not to happen. 4.3.3 The availability heuristic A very weird but common bias, is to overestimate the importance of information immediately available to us. An important example is that we estimate the prevalence of crime by how easily we recall instances of it. For example, people consistently overstate the toll of terrorist victims (which are fresh in the mind with incidents constantly reported) yet understate the toll of traffic accident victims. 4.3.4 Survivorship bias Related to hindsight bias, a common mistake that comes from considering surviving examples. Thus, entrepreneurship seems easy as we hear little about businesses that fail and disappear. When we seek to emulate those who were successful, without recognising those who did similarly were unsuccessful, we fall prey to this bias. Bill Gates dropped out of college, but not many college dropouts do as well. 4.3.5 Overconfidence bias We obviously and strikingly overestimate our abilities while underestimating our overconfidence, leading us to take far greater risks than otherwise, hence the recklessness of youth. 4.3.6 The Dunning-Kruger effect Those with high expertise have a strong tendency to underestimate their expertise and those with low expertise have a strong tendency to overestimate their expertise, which interacts badly with the overconfidence bias. 4.3.7 Narrative bias The tendency to put strong faith in information that fits well with a good story. 4.3.8 The ostrich effect A tendency to ignore dangerous or negative information, which is related to confirmation bias. 4.3.9 Selective perception The tendency for expectations to influence how strongly we perceive things. This is particularly important in pain management. 4.3.10 Zero risk bias Humans are very poor at estimating risk, so even small risks can cause stress, leading us to prefer certainty even though it may be counterproductive. This is an important consideration in counselling patients about procedure risks and disease outcomes. 4.3.11 Pro-innovation bias The tendency to overestimate the usefulness of something if it shows novelty. 4.3.12 Anchoring bias A puzzling tendency to over-rely on the first piece of information encountered. Thus, the first number suggested tends to frame a negotiation over price, or affect a subsequent quantitative estimate. 4.3.13 Clustering illusion The tendency to see patterns in random events or data, such as seeing faces in the clouds. 4.3.14 Choice support bias The strong tendency to feel positive about something you have chosen or publicly support. This is why your own dog is great even if no one else thinks so. 4.3.15 Recency bias Believing (for no reason) that newer data is more reliable than older data, and that recent trends have a high likelihood of continuing into the future. 4.3.16 Bandwagon effect That well known tendency of other people to adopt a belief based on how many people believe it. 4.3.17 Blind spot bias, or cognitive bias bias Lack of recognition of our own biases while being aware of the biases in others. 4.3.18 Research and the scientific method Even though we are influenced and affected by many different ways to make mistakes, there are also many different ways to overcome them. In science, the most obvious way is the systematic checking of ideas and concepts against reality. There are many ‘thinking tools’, such as the refinements of philosophical logic (e.g., induction, falsifiability and paradigms), statistical analysis, controlled experiments, peer review, seminar presentations, writing grant applications and a plethora of other features of the culture of science. Together, these are potent (if not always efficient) ways of tackling biases. Even so the struggle continues, as is evident in the low rates of reproducibility emerging in many areas of research. First and foremost, be mindful of biases as they never go away. 4.4 The replication crisis in medical research Many articles have appeared over the last ten year years in serious and august journals such as Nature and Science describing (and expressing alarm at) the low reproducibility of scientific findings in many fields. This is a very significant issue, and bad news because it is reproducible observations that form the bedrock of science. For this reason it is important to know something of the nature of the problem and the think about the implications for one’s own work. When an observation or experimental result is easily replicated by others it can be accepted as solid progress, can be used as a verified fact in scientific discussion to support arguments and is a sound basis for further progress. However, replication studies attempting to reproduce the central findings of prominent published work have indicated that an alarmingly large proportion contain flaws1,2,3. This may not be entirely surprising since most worthwhile scientific studies are technically hard to perform, which makes replication difficult, but the problems go deeper than that2,3. Poor replication may go some way to explain why so many promising drug targets fail in the early stages of drug development. Clearly, however, there must be implications for a poor clinician trying to avoid wasting time on a flawed project. 4.4.1 What studies can be trusted to form a basis of new work? There is no straight answer to this, only general rules of thumb. A simple one is that older studies have more information that help judge trustworthiness. Thus, if a study has been cited by others and its outcome repeated successfully over a long period then more weight can be placed on it. A study on a clinically important topic from 10 years ago has had plenty of time to be reproduced and built upon, and if it has not (perhaps evidenced by absence of later related publications) then it may not be wrong, but it needs to be marked down. Unlike an old study, a recently performed study may be perfectly executed but it has not had time to earn as much trust. Studies where the outcomes or observations are made by a simple method, giving less chance of systematic errors, can be more robust. Another good indicator is that a study reports secondary independent parameters that help to validate the main outcome. Thus, patients receiving treatment may improve a targeted function (e.g., limb mobility, cardiac output, urine flow) and show sustained lifestyle improvements that should be an expected correlate. Other indicators include blinding of researchers during the study, publication of all data (not just selected data), and appropriate statistical tests. 4.4.2 What about peer review? Are reviewers no good? Peer review must be viewed as a filtering system of quality control and is well accepted as far from perfect, although it seems to be the least imperfect (and most practical) devised so far. Alternative assessment systems exist such as online feedback on bioRxiv preprint manuscripts but have yet to achieve traction. There are two particular issues of note with peer reviews. The first is that reviewers can only judge what is put in front of them and ferret out flaws they can detect, and most do a good job at this. A perfectly executed study may give outcomes that no one can repeat because of some obscure issue: an unstable drug, faulty computer code or a biased patient sampling not evident in the manuscript. The second issue is that journals (and peer reviewers) can themselves be part of the problem. They expect novel exciting and important results. This creates huge perverse incentives for authors to provide that. If a fascinating outcome has not been seen by 99 researchers but is seen by 1, whose study will be published? This is the well recognised problem of publication bias, and is proving hard to fix. 4.4.3 Why is this happening? There is a long list of factors adding to replication issues. Pressure to publish (for career enhancement and obtaining funding to support the work), poor usage of statistical techniques (very common), protocols that are difficult to follow and studies that have a high risk of systematic bias in collecting data - these are all examples of contributing problems. Making all this worse are the systematic and cognitive biases that affect researcher judgement - we fool no one better than we fool ourselves. 4.4.4 What can be done to avoid this type of trouble? There is no panacea, but the classic scientific virtues will go a long way: good experimental design, robust critiques of the work from many sources, a high quality of statistical analysis and interpretation, good mentorship, extensive documentation and a painstaking approach to performing well even the smaller aspects of study protocols. It is also important to be aware of the impact of our own cognitive biases, which we underestimate, and the fact that the scientific method has evolved to overcome these biases. This can be seen in clinical studies, for example, in the need to take seemingly excessive trouble over blinding of both subjects and researchers. 4.4.5 Is there no hope? There is hope, as replication issues have gained a great deal of recognition, leading gradually to improvements. Publication bias is being addressed, and publication of purely replicative papers more acceptable. Preregistration of clinical trials and systematic reviews are now a requirement. A new focus on statistical rigor is evident in journal submissions, and more powerful analysis methods gaining traction. One is the use of a Bayesian statistical framework, which this needs some trouble to use. This views a piece evidence not so much as proof but as a modifier of a prior belief, to a degree that depends on the strength of the evidence. This approach leads to a conclusion we can instinctively accept: that extraordinary claims need extraordinary evidence, but less so with less extraordinary claims. Thus, smudgy photos may be proof to a court of a speeding offence, but poor proof of Martians among us. Another hope is the emerging clinical practice of systematic review and meta-analysis of prior studies. Not only does this involve careful assessment of biases but it aggregates studies that have their own features (good and bad), and so a diversity of practices may average out and ensure that outcomes can have some weight placed on them. There are also many other emerging recommendations designed to help ensure better reproducibility, some of which can be surprising. It is a good idea to read up on the subject and take it seriously. A bracing place to start (if a little technical) may be the famous inflammatory essay by John Ioannides “Why most published research findings are false” in PLOS Medicine 2005 (DOI: 10.1371/journal.pmed.0020124) or the interested researcher can enter the terms “scientific reproducibility” or “scientific replication crisis” into a search engine and stand well back. Begley C G et al. (2012). “Drug Development: Raise Standards for Preclinical Cancer Research”. Nature. 483: 531–533. PMID 22460880. Allison DB et al. (2016) “Reproducibility: A tragedy of errors.” Nature. 530:27-9. PMID: 26842041 Ioannidis, JPA (2014). “How to make more published research true” PLoS Med. 11:e1001747. PMID: 25334033 4.5 Survivorship bias This a logic flaw that is very pernicious because it can be so hard to spot. Survivorship bias is commonly seen in popular journalism, but mercifully occurs far less in scientific work since the scientific method usually shields us from it. It is important, however, to be aware of it any clinical research setting, particularly when designing new studies or constructing research questions and hypotheses to be tested. To illustrate the effects of this bias, imagine that a few months before September 11 2001, US aviation authorities bring in a rule requiring the aeroplane flight decks be inaccessible during a flight, rendering impossible the terror attack on the World Trade Centre and Pentagon*. Imagine also that an international pandemic prevention team rapidly identified an infectious new coronavirus in bats in central China and within a week produced a diagnostic test and enforced a short lockdown in towns nearby, blocking its spread. In both of these scenarios history would be changed, but later we might complain about inconvenient restriction of movement for aircraft captains or question the huge cost of a pandemic preparedness, since ‘nothing’ had happened. These illustrate some of the traps and consequences of Survivorship bias – we cannot see things that do not happen, but which might have. 4.5.1 What exactly is this bias? Defining this bias in simple terms is not easy. We can formally describe it as failing to see things that do not survive a selection process; we thus fall for the bias when we see only those things surviving selection and assume they are representative of the whole. However, this type of definition of Survivorship bias is not very helpful as it does not convey why the bias is so often invisible, which is the real problem. Often (as in the scenarios above) it is because we are only dimly aware that a selection process even exists. In other cases it is complicated by other mental biases such as Hindsight bias (i.e., considering that things that happened in the past necessarily had to have happened); this bias can, indeed, be seen in the scenarios above. It is usually more helpful to work through illustrating examples. 4.5.2 So what examples might help? Examples from popular journalism are everywhere, such as discussing the great strategies of successful people in a field (such as wealth accumulation or finance) without considering those people who followed the exactly the same strategies but who failed. The latter group are hard to see since they tend to exit the arena. Clearly, adopting a strategy based on such incomplete data is dangerous as it leads to over-optimism. For another example, we admire the beautiful and functional buildings built in the past without considering that any ugly and badly constructed building were demolished years ago. Most ancient Roman dwellings, for all we know, may have been horrible. Historians by the nature of their work are highly subject to Survivorship bias as they study documents and artefacts that have survived the years; they cannot easily study what might have been or what was lost. A slightly happier story can be seen in the introduction steel helmets in world war one trenches. When French Adrian and British Mark 1 helmets were worn there was an increase in soldiers being treated for serious head wounds, and it was widely supposed that there was to some defect in helmet design. In fact careful analysis of the data by army medical staff showed that this was actually due to improved survival of soldiers hit on the head. i.e., without helmets soldiers would not survive to be treated for their head wounds. This illustrates that the logic error arises from the perspective of the data-gatherer who only notices the increases in head wounds, but it also shows how this bias can be overcome. Lastly, there is the apocryphal but entertaining story of the scammers who sent weekly messages predicting stock market up or down movements to potential investors. To half they sent predictions of up, the other half predictions of down. If the market went down they sent no more messages to those who received a prediction of up; to the remainder, half were sent new (random) messages predicting up and half predicting down. And so process repeated. This continued until most investors were dropped. By this time a few investors had had a long run of correct predictions and with such ‘proof’ of the scammers competence, sent them money. The trap was the newly impoverished investor’s perspective: they could not see they were a survivor of a random selection process. 4.5.3 Where does this bias crop up in clinical research? The most obvious is in publication bias, where only exciting positive trial results are published and we cannot see the unpublished negative results. This can be dealt with using the techniques of systematic review and meta-analysis. When designing a study we must be alert to how survivorship bias may affect outcomes, for example if a subset of a group under study may systematically drop out over time. Hypothesis construction may be based on datasets where outcome evidence may be missing or biased; it is not necessarily fatal to have a flawed basis for the project hypothesis (since it will be tested), but it will affect weighting of priorities and funding justifications, and may lead to time wasted. Survivorship issues can crop up whenever a selection or stratification step is made in data analyses. Interpretation of clinical outcomes becomes a problem if some outcomes are not recorded (so cannot be seen), and this is classified as a study design flaw. This is well understood in clinical trials and is dealt with by the technique of censoring. 4.5.4 How can a researcher minimise or avoid this bias? Half the battle is simply to recognise that it can occur, and it is useful to think about where it might happen in your work – which is really the point of an article like this. It can be an example of an unknown unknown, that is, a problem that we are not aware could exist so we are completely blind to it. That being the case the way to tackle this is by adopting a routine strategy to detect it, such as checking if all participants entering a trial have an outcome that is recorded. Another approach using data is to construct a prediction model which can then be cross-validated on other datasets. This can reveal the presence of biases, including survivorship. This example taken from Nassim Nicholas Taleb book “The Black Swan”. 4.6 Parkinson’s Laws and related project planning pitfalls for researchers While project management need not be a formalised process it is important to consider it carefully. As if research were not hard enough, there are a number human peculiarities that creatively combine to frustrate project advancement, so a few are briefly noted here as an alert to some general obstacles to watch out for. Some of these are helpfully named after those that first identified them, as with the first example named for C. Northcote Parkinson and his eponymous book. 4.6.1 Parkinson’s Law The great law of bureaucracy, namely that “work expands so as to fill the time available for its completion”. Not disastrous in itself, but gives a warning about an odd trap often seen in project work. A time allocation may be appropriate for a project, but often a deadline it is some distance in the future so can be admired from afar. That means that for now endless discussions and meetings can be scheduled about it, and collaborators may not necessarily prioritise it. Only when the deadline nears do substantive things tend to be done, but the potential problems with this approach is self-evident. 4.6.2 Fredkins paradox and Buridan’s Ass (or Buridans principle) Edward Fredkin: “The more equally attractive two alternatives seem, the harder it can be to choose between them—no matter that the choice itself may matter little.” A similar idea to this is the story of Buridan’s ass, a poor animal that starved to death because it was sitting between two equally alluring piles of food. It can often be more important to make a decision than be paralysed making the perfect decision. 4.6.3 Bikeshedding Also called Parkinson’s Law of Triviality from an example given by Parkinson himself. This concerned a council committee asked to approve the local construction of a nuclear power station and a shed for parking bicycles. The committee would take far longer to approve the bike shed that the power station, since no one really understands huge undertakings like power stations but everyone on the council has opinions on bike sheds. While a nuclear power station would be more controversial now than in the 1950s, the point is that easy trivial things can take up more time than big hard things, and we need to watch out for this. 4.6.4 Hofstadter’s Law “Hofstadter’s Law: Complex tasks always takes longer than you expect, even when taking into account Hofstadter’s Law.” Everyone has encountered this. 4.6.5 Procrastination Many books have been written about procrastination and how to overcome it, and everyone has their own weaknesses in this regard. If procrastination (i.e., avoiding work on a project) is a persistent problem, the first task is to recognise that it is so, and think why. Actually finding ways to overcome it is another matter but a great deal of helpful advice is available and here the internet is your friend. This is a huge subject that cannot be summarised in any detail here, but typical approaches involve dividing a task into many small tasks that are less easily avoided, good time management, examining the root cause of the avoidance and (in extremis) giving the task to someone else. The tyranny of small decisions, and of path-dependence This refers to the fact that lots of small decisions by many people taken for perfectly good reasons at the time can aggregate over time into something undesirable. In the same way many reasonable small actions affecting a project can aggregate to something bad, and the ways forward for a project limited by decisions made in the past. Such path-dependent problems can be hard to solve without starting from scratch which is often a costly option. 4.6.6 Unexpected developments and mission creep Any scientific project can take a left turn, where some curious or exciting experimental result occurs that distracts from the core business of the study. This can lead to changes in the research plan and makes the mission or scope of the project larger. This needs cautious management as it can result in missed deadlines if not brought under control. A new and unexpected observation may be an opportunity but may be a distraction and it takes some wisdom and good mentoring to tell the difference. 4.6.7 Unclear responsibility or accountability Who is responsible for making sure that an aspect of the project is done? What will keep that person honest or accountable? If there is nothing, how can that be handled by the person in charge of the project? 4.6.8 Soft deadlines Soft deadlines, i.e., deadlines that pass with little consequence, can be a real pest because no one respects them. If a project deadline is a definitive (i.e., hard) one, then deadlines agreed for the various milestones of the project have to be adhered to and usually are. In contrast, soft deadlines can be a paradoxically hard to keep on track with, and may be a big contributing factor to Hofstadter’s Law. Combined with Parkinson’s Law, soft deadlines can be serious nuisance. 4.6.9 Communication It is important that this is timely and done well to make sure that everyone working on a project is kept informed but equally important the that they are not overburdened with irrelevant material. There are now many online tools to facilitate this. "],["presentations-at-conferences.html", "Chapter 5 Presentations at conferences 5.1 Poster presentations 5.2 Conference oral presentations 5.3 Giving presentations and lectures – general considerations 5.4 Preparing slides for an oral presentation", " Chapter 5 Presentations at conferences 5.1 Poster presentations Posters are a very important form of presentation at conferences and nearly all researchers will present them at some time. The following are important considerations for poster preparation and presenting. A conference poster is typically a large sheet of card, plastic laminate or other stiff medium on which is printed details and images describing a study and its outcomes. It is displayed pinned-up at designated sessions, typically with an author present, and is accessible for conference attendees to scrutinise at leisure. It uses a similar structure to a research manuscript, i.e., title, authors, abstract, introductory review, methods detail, data and conclusions, but has to be extremely abbreviated. It has a lower status than an oral presentation but is an excellent way to communicate with many advantages over a short talk, in particular, it is less ephemeral and allows in-depth discussion in front of the printed-out details. Posters are ideal for attendees walking around to scan rapidly to find content of interest, especially for those less confident in English. Personal discussions in front of posters can be pivotal in forming professional connections, and to engage with detailed criticism of the work. Like oral presentations, posters are often the prelude to full journal publication, but may simply be used to get expert feedback. As a learning exercise it is good to read some posters and assess how easy or hard it is to follow the work; however, note that posters, like talks, are an exercise inefficient communication, not in perfection. 5.1.1 Poster (or presentation) abstracts These are submitted according to instructions long before the conference. They resemble in form a manuscript abstract, standing self-contained without further information. Phrases like “these outcomes will be discussed…” are frowned on. A committee will assess abstracts, with the highest-scoring ones selected for oral presenting, the rest as posters. This does not always reflect the quality of the work. 5.1.2 The three main types of poster viewers Many conference attendees will have no strong interest in the subject of your poster and will walk past scanning the title and any striking images. Most people do not have the time to look at posters outside their own areas unless the conference is small. Attracting a general audience means the poster needs a short and informative title, minimal text and good figures (and nice images) that tell a clear story. The second group of viewers are those with an interest in your area of work – they will take time to read summaries, introductions and figures, but ignore fine details. They should come away from your poster with a good idea of the study and the data. The third group have strong interest in your area and in what you have done so will take time to read everything, including methods and references that others will not bother with. They will mind less about small fonts with long sentences as they are motivated to read it. If you are there they will usually ask you to explain the work to them and ask questions. Note this group includes poster award judges. 5.1.3 Poster titles These should be clear and in very large font (perhaps 60 point or larger) so can be read from a distance, and should be phrased tersely to describe the key points of the study and its outcome. Beneath it should be a list of authors and their affiliations in a less prominent size and style. 5.1.4 Poster summary Include a copy of the conference abstract if you must (it will be in the conference abstract book) but it is usually best to include on the poster a short summary in font readable from about 2 metres, using curt and easily grasped sentences with simple and concrete aims and conclusions. 5.1.5 Poster introduction This should be brief, large font and short sentences. It should state the nature of the problem addressed by your project, the broad sweep of current knowledge in the area and how you tackled it. 5.1.6 Materials and methods No-one will read this unless they are really interested (or it is a methods poster), so write this as you wish but don’t put it somewhere prominent that distracts from your more important poster elements. 5.1.7 Data and analysis A poster needs to be visual and with an appealing layout and handsome looking Results figures. Results should not be principally in text form, but graphs, simple tables, diagrams and images which are easy to digest. These should be well labelled, with legends on or directly under the images/tables themselves. Use colour for emphasis of key data features, and use summary diagrams if appropriate. 5.1.8 Conclusions and summary of results Ideally use large text font and present as short, concrete dot points. 5.1.9 References Keep these to absolute minimum in small text tucked away at the bottom since very few will need this information, but it is good to form a habit of referencing supporting literature. 5.1.10 Poster structure The rule is to keep everything short (if in doubt, leave it out) and visually uncluttered. Keep the poster simple and easy to scan, and remember most attention will be on the upper part of the poster, so put boring details (e.g., Methods and Acknowledgements) low down. If you want to divide the poster into columns make it obviously so. It is often useful to group related materials in panels of subdivisions. 5.1.11 Discussing the poster You will be asked about your poster (which is what you want) so take some time to prepare answers to simple questions and think about how to respond to a request from a viewer to “take me through the poster”. It is an opportunity to shine even if you have to keep repeating yourself to different people. 5.1.12 Conference etiquette Stand by the poster (if possible) when conference organisers indicate, so those interested to do so can find you. This does, however, limit the time you can spend looking at other posters, so either arrange for a co-author to help or do not stray too far away. Ask those loitering at your poster if they would like you to explain the work to them, but do not hector. Never photograph other people’s posters without explicit permission as their work is probably unpublished. 5.2 Conference oral presentations An oral presentation can take several forms but here we consider the short abstract presentation. A conference oral presentation is quite a different beast to an invited seminar, where a presenter holds forth on their subject of expertise for half an hour or more. It is usually chosen from among the best ranked abstracts and involves present a piece of research work in 5 to 15 minutes, depending on the session. The shorter the presentation the harder to prepare; it is far harder to prepare than a long seminar as studies always contain complexities not easy to describe in a brief way and there may be several important study stages to describe. They are thus information dense, so must be highly structured with easily grasped slides and clear wording well-honed beforehand to ensure a good and confident flow. When preparing, remember how often you suffered listening to presentations that were boring with rapid-fire speech and slides that were impossible to read. Resolve to do better. 5.2.1 General principles The first principle is that to know your audience and their level of understanding, and treat them with courtesy and respect. No matter how clever individuals in the audience may be, you are trying to communicate rapidly a lot of complex information. Therefore, you need to make it mentally easy for the audience to follow: use unrushed speech patterns, theme repetition, consistent colouring schemes and uncluttered slides. Remember how fleeting your words and slides are to them, unlike printed text and images where a reader can linger or revisit difficult points, so prepare the talk with this in mind. 5.2.2 Title slide This is useful to include at the start but the chairperson will usually state the title and authors so the presenter can just move on from the title slide without further comment. 5.2.3 The first sentence It is crucial to get the first sentence right, so pick a short sentence easy to say (and remember), so after that everything should go well. Ideally, it is engaging enough to grab the attention of the audience. 5.2.4 Introduce the work Concisely summarise the subject and outline the research question and why it is important. You may also want to include formal hypotheses, but it depends on the presentation. 5.2.5 Speak … very … slowly To present well you should not speak fast, which makes a talk hard to follow. It also sounds nervous. Speeding up unconsciously as a talk goes on is common, so it is useful to pause at important slides and start again slowly. A slow, measured pace sounds nice and confident, speeding up for less important points and slowing down to emphasis. It may feel like talking to a slightly dim child but, surprisingly, it will not seem that way to the audience. Speak into the microphone (harder than it sounds) and project ENTHUSIASM!!! Or fake enthusiasm, your choice, but it helps the audience engage with your work. 5.2.6 Laser pointers and presentation equipment Use laser pointers sparingly and do not wave it around. Familiarise yourself with slide control and laser pointer beforehand, and check slides with animation or movies run on the conference system. 5.2.7 Slide qualities Do not use too many slides - an average of 40 seconds per slide is often reasonable. Graphs, tables and images must be easy to read quickly, with large (&gt;16 point) bold fonts and short labels. Titles should be short and informative. Use fly-ins to help emphasise points, but most other animations distract. Blocks of text are best not to go beyond 2 lines or they will be hard to follow. Do not overburden the slide with information and omit irrelevant features that will add to visual confusion; e.g., do not put many literature references in as they clutter and are not easy for audience members to look up. When speaking over text do not read it droningly, but slightly paraphrase in a conversational way. Use colour schemes to help comprehension so, for example, if controls are green on one slide make them green on others. The audience has a brief time to take in a lot – make it easy on them. 5.2.8 Graphs It is best to step an audience through the graph from left to right and explain major features as you go. Make x-axis categories match later slides (where relevant), so are easier to follow. 5.2.9 Summaries and conclusions At the end of a talk, run through a text or diagramatic summary which reflects the content of the talk but keep it short. Conclusions should be exactly that, and not just repeating a summary; be clear how it relates to the evidence presented in the talk. 5.2.10 Acknowledgements slide Always include one of these. It will mention funding and other support and collaborators, but (unlike seminars) thanking your co-authors is unnecessary as, implicitly, you are speaking on their behalf. 5.2.11 Practice After working out the words and slide content, practice many, many times. If you do this you will remember your words as you present and it will flow nicely, but it is usually not best to memorise a script as it is hard to pick up the thread again if you stall. Use notes as a backup and to provide reassurance in case you dry up. When practicing, note the places where you stall, and alter slide or the phrasing prevent stalling on the day. 5.2.12 Questions Take this seriously, and get people to pitch hard and soft practice questions to you to guage your response. Prepare for defending particular flaws that you know exist in the talk, but remember many questions will be simpler than you imagine and some will be completely unexpected. If you are a student it is reasonable for your supervisor (if present) to step in to deal with a tricky question or one that needs a lot of background knowledge. If you do not know the answer to a question you should say so (don’t just wing it), but try and provide a little more comment than simply “I don’t know”. 5.2.13 Fear and stage fright This is unavoidable if you are inexperienced, but having lots of practice helps inspire some confidence. Beyond that it must simply be endured, be consoled that it will get easier with practice. However, it is important to be aware that the audience almost certainly knows much less about the topic than you do. If the rows of faces seem intimidating, focus on one or two people in the audience can help. Some say it helps to imagine the audience with funny hats or something else distracting, which is questionable, but use whatever you find is helpful. 5.3 Giving presentations and lectures – general considerations It is a normal and expected skill for a surgeon or clinician to be able to give an extended presentation at a conference or seminar. A lot of presentations are not that great, or are actually hard to understand, so if your presentation is good and clear it will stand out. Good lecturing is a skill that needs to be nurtured and continually improved, and it is rare for anyone to do it well all the time. It is not simple to pin down why a presentation is easy or difficult for an audience to understand since many elements need to work together. Common culprits in poor lectures are slide complexity, unintelligibility of the talk structure or narrative, poor speaking clarity and too much knowledge assumed of the poor audience. Bear in mind that, no matter how impenetrable the presentation there are often audience members with impressive concentration, experience and intellect that ask cogent questions at the end, but that does not mean the presentation went well. It is useful to recall that a lecture or speech is linear: there is an utterance and a slide projected, then they are gone. The audience cannot easily go back and check something as they can with a written text. The audience must struggle on. However, information is not linear, so lectures employ a number of devices to improve understanding. One is to use a familiar structure, so the audience is introduced to information in an accustomed sequence that is and easily grasped, with the importance of particular elements clear. Repetition helps. Focussing on a small number of points (usually three) is effective. Rhetorical skill and clear diction are needed. Repetition helps. At the end is a summary, and after that the audience can ask for clarifications. This approaches should maximise information transfer. Also, repetition helps. 5.3.1 You Dress as convention dictates so you are not a visual distraction. Speak in measured and modulated tones, not monotone, and don’t say ‘um’ more than a few times. Speak unnaturally slowly, but speed up now and again. Smile as much as is consistent with an appearance of sanity, and above all sound interested and enthusiastic about your material. Enthusiasm makes a surprising difference. The attention of the audience should be between the slides and the speaker. Use the slides to present your concise points and your voice to elaborate. 5.3.2 Practice, and the surprising difference between the written and spoken word The above considerations mean that the talk needs to be practiced a lot, and feedback obtained from others. This practice needs to be repeated until you recall everything easily and sound confident. Hopefully others will tell you where you fall short. Alternatively, record yourself, then listen and all will be revealed. However, when stringing sentences together you may be surprised at how a sentence or phrase seems fine on the page but sound terrible and stilted when utter aloud. In most case it is just that written convention we are used to do not match well with natural speech patterns. In any case, be wary of giving a talk without practicing it out loud at least once. 5.3.3 Slide clarity Slides have two functions –as a visual aid and to present specific data. It is hard to get sound advice about how to make good slides, except directly from a mentor, but there are some easy points to remember. Slides need big font size to be read easily from a distance. They should be uncluttered, with information content that is not too dense because the audience has limited time to absorb it. Graphs should be easy to interpret, with minimal complexity and as little text as possible. Summary diagrams and simple visuals can help a lot. Do not use big blocks of text longer than 2 short lines, and use dot points. These and other simple considerations are so often disregarded that just adhering to them can make a presentation stand out. In general, having good slides always involves showing them to other informed and opinionated people. 5.3.4 Ask other people Good presentations take a lot of work to get right. Only experience will make things better, but experience takes time. It is far quicker to survey other people their opinion of your talk. Ask a variety people and listen carefully, especially to how well they interpret your slides. If they can’t understand parts of your talk you absolutely must rethink those parts and how you present them. Also, be patient with them and check that they really did understand, and are not being polite, or are misunderstanding important points. This process can be bruising for the ego, but must be done because you know so much more than your audience that it is hard to put yourself in their place. 5.3.5 The audience What will the audience expect from your talk? Why are you addressing them? What knowledge can you assume they have? How will they vary in their knowledge background? These are issues that must be clear for the speaker. It is not a good idea to launch into a deep jargon-filled technical explanation without introducing the subject (and the jargon) carefully to the audience: eyes will glaze over for sure. 5.3.6 Get your opening lines right. Very important. 5.3.7 Explaining things If there are concepts used that are not common knowledge they should be briefly introduced and their importance outlined. Don’t take too long, but explain in as lay terms as possible. Once you have explained your concept in terms that a 12 year old will understand the audience will be with you (unless they are all 11 years old) and you can use that concept freely. There will always be some concept you take for granted that others do not, and it is not always easy to spot those. Again feedback and questions from others will enlighten you about how well you explain things. You will improve with time. 5.3.8 Say three things. A common and useful guide to is to introduce only three major points in a talk. Nevertheless, detailed technical points should not be shunned. It is often useful to restricted them to an identifiable part of your extended presentation, where those who know they will not understand or care can switch off for a short time, and come back later to focus on your three main points. 5.3.9 Notes Avoid using notes if possible, however, notes (and PowerPoint presenter mode text) can help to keep the talk on track. If using notes do not simply read them verbatim – they will sound terrible. 5.3.10 Using quotes and epithets It is often a good idea to use interesting quotes, light anecdotes and the occasional curious observation in a talk. It allows a little relief and punctuates the lecture, especially if it is getting a bit dry. Invite interjections if you can, as that serves the same purpose and can help make sure the audience is with you and thinking, or at least awake. 5.3.11 Be merciful to your audience Do not pack much into half hour talk. Don’t make it intense and hard. 5.4 Preparing slides for an oral presentation A good slide presentation that is clear and easy to understand, making points that hold the audience attention always makes a favourable impression. Using well designed slides is central to making that impact, yet many presenters take too little time thinking through and designing on their slides. Inexperienced presenters can also be very defensive about their bad slides when developing them since, presumably, the slides are clear to them and they put a lot of work into them. Most people in the audience will be kind about bad slides (especially if the presenter is clearly inexperienced) and even experienced presenters use some shockers on occasion. Slide presentations are an exercise in efficient transfer of highly condensed and complex information from presenter to audience members. Achieving this transfer involves a very different set of skills to those needed to write a manuscripts or lead tutorial. With that in mind, below are a few points to consider. 5.4.1 Avoid clutter The audience has a very short time to decode what the slide is saying, and having too much dense information will impede that. The eye needs to be drawn to points of interest that can easily be understood. Related to this… 5.4.2 Don’t use big blocks of text Reading a lot of text while someone is talking is tricky. Reading a big block of text while the presenter is reading it out is not tricky but is not the most effective use of time. Text on slides need to be digested easily and quickly, so the text has to be broken down into smaller blocks that are visually easy to gasp. Often short dot points are good. 5.4.3 Text size should be large and bold font Large text is easy to read. 18 point font often works well, with larger for titles. Using a sans serif font like Aria looks good for projections, but whatever is used should be consistently throughout. Don’t use shadowing on fonts as a rule, as they can look confusing at a distance and underlining similarly is less effective than on the page. 5.4.4 Make the presentation highly structured Presentations should be predictable, broken down into easily understood sections on slides with similar style and layout. Information presented across several one slides should use similar colouring conventions to allow cross comparisons. 5.4.5 Don’t try to make a lot of points With one slide it is usually best to make one main point or present one set of data, unless the slide is a summary slide. 5.4.6 Be careful with data tables Data tables can be hard to read at a distance if large and can be hard to follow if visually complex. The technique here is not to put everything on screen in tiny writing and talk vaguely over it. Few people will follow it if they have not seen that data before. Minimise the amount of data presented if possible, and make its structure simple. Use colour and bold judiciously to emphasise particular data point and use fly-ins (if using PowerPoint or similar package) in sequence to highlight points judiciously as they are mentioned. The technique is to step through the data in a structured way which helps the audience understand and read the data. First introduce the data and what it represents (with an informative title above), describe the data categories then mention salient features and important points. It is hard takes in a data tables quickly without guidance from the speaker. 5.4.7 Be even more careful with graphs As with data tables use colour, bolding and occasional fly-ins to delineate the major points of interest in the graph and step through the data in a highly structured way. Make sure that text is highly legible at a distance. 5.4.8 Avoid excessive referencing Referencing work is a good habit, but it can be distracting and the audience cannot easily check it in a talk. The best approach is a simple reference at the bottom of the slide. 5.4.9 Use pictures and images where possible. In a multimedia presentation it is much easier to use illustrative pictures rather than blocks of text, so they should be used liberally. Put any text close to the image it refers to. It helps the speaker remember what to say if the slides are distinctive. Having too many images is usually referred to as having a ‘busy’ slide and that is never a compliment. 5.4.10 Length of talk As a rule the longer the talk the easier it is to do it. Short talks have to leave out a lot and compress the information they are communicating. Long talks don’t, so they don’t need to be as carefully structured. 5.4.11 Use colour carefully Make sure that colours contrast well and are highly visible on the screen. It is often a good idea to check this before the talk as a test with a projectors. Avoid garish colours unless impact is needed, and then don’t overdo it and bombard the audience till they flinch. Dark text or shapes on neutral light background works well. Flashing or spiralling colours should not be used as they are very distracting in a talk. When presenting a theme across several slides it is best to use the same colours – e.g., if survival rates of group A are red and group B blue on one slide, use the same colours for group A and group B data on other slides. This makes the data much easier to follow. 5.4.12 Check grammar and spelling It is strange how easy it is to miss mistakes when the text is large.. 5.4.13 Don’t put in too many slides Too many slides for a fixed length talk means too much rapid talking. Since talking needs to be slow and measured, that is bad. A rule of thumb is one slide per 40-60 seconds, but it depends on the slides and their complexity. 5.4.14 Practice the talk Always a good idea to do this. Check the presentation works well, especially any inserted films. 5.4.15 Show your slides to someone else Present the talk, or at least the slides to someone else as you prepare. There is so much that we do not see in our own work it needs the perspective of another person. If you remember nothing else, remember this. "],["publishing-manuscripts.html", "Chapter 6 Publishing manuscripts 6.1 Writing skills for manuscripts 6.2 Manuscript publication and authorships 6.3 How to collaborate on writing manuscripts. 6.4 Producing the first draft of a research manuscript 6.5 Manuscript citations 6.6 Writing manuscripts abstracts – one of the hardest writing skills 6.7 Writing a manuscript introduction 6.8 Writing the Discussion section of a manuscript. 6.9 Performing a journal peer review 6.10 Responding effectively to a manuscript peer review", " Chapter 6 Publishing manuscripts 6.1 Writing skills for manuscripts The findings and insights gained in the course of a project have to be communicated to others in an acceptable style and format, which is why scientific manuscript writing is an essential skill. While there is some room for creativity, manuscripts are for communication and, by and large, are not fun. The conventions of the published scientific manuscript have evolved over centuries and gained universal acceptance as a superbly flexible vehicle for describing all the aspects of piece of scientific work in a compact manner. The only sure way to master this writing skill is long hours of practice and constructive criticism. While that is happening, here are some useful points to consider. 6.1.1 Styles of writing used in a manuscript It is useful to think about a piece of medical or scientific writing in terms of its style characteristics or parameters. There quite a few of these, but the most important would include: Journalistic vs dry scientific style. A highly journalistic piece of text has a colloquial or even gossipy style, with interjections of opinion, interesting diversions, human interest points and phrasing chosen for colour and impact; it is easy to read. A dry scientific style has none of these features, rather is has has tightly linked sentences, focusses directly on factual detail and interpretations directly arising from these details. It has high precision but can be hard to read. Most scientific manuscripts are towards the dry end, narrative reviews may flirt with the journalistic style in parts. Text density. Highly dense text, particularly used in abstracts, packs in as much as physically possible and shaves off any non-essential words. Comprehension suffers with high density so structure and clarity are crucial. High density text is often but not always seen with a dry scientific style. Scientific manuscripts, aside from abstracts, need to be in the middle of this scale. Degree of specialism. How many jargon and technical words to use without definition is important to match to the expected audience. In addition, specialist fields have common conceptual assumptions and accepted types of phrasing and description that must be adhered to, but make it hard for the non-specialist. Text complexity. This is usually defined as reflecting the number of long words in the text. As a rule this should be reduced as much as possible in medical/scientific text, but is usually high. 6.1.2 Starting manuscript development To decide roughly on the style needed it is important to read articles from the journal where the manuscript is targeted. Most strictly scientific original research articles have a similar style and structure, but outside this category there is a lot of variation. Once the style details are decided, the first step is to define the focus of the article, which for an original research article or systematic review is a specific and tightly defined research question. If data analysis is involved this must be prepared this first as everything else hangs around its interpretation. The text then must be fleshed out, clarified and revised many many times. Ask others to give criticism and, when it is given, accept it with grace and take it seriously. 6.1.3 The story Having a narrative that gives a structure to the central points of your manuscript will help give it clarity and make it more engaging and easy to read, which are major goals. The components of the work is described in an order that brings out that story, but note that this is not usually in a rigidly chronological order of events. Bear in mind that a narrative can be powerful for what it leaves out, as much as what it includes, so omitting trivial detail and relegating extra or negative information in the supplementary sections can help. 6.1.4 Clarity A manuscript is an exercise in communication, above anything. It is often a record of activity, such as a systematic study, but this cannot be presented in an unfiltered way without compromising clarity and without clarity there will be no comprehension, and without that the manuscript will not make it through peer review. Thus care is needed with grammar, sentences that are short with consistency of descriptors, preference given to concrete words (rather than abstract highfalutin latinate circumlocultions) and without undue overuse of adjectives. In the end, other people must be the arbiters of clarity, so it is wise to have this checked. 6.1.5 More about clarity Keep sentences below 3 lines, if single column A4 is used. Use reasonably short paragraphs that contain linked ideas and link paragraphs where possible to keep the flow of the narrative. Try to sound precise and slightly fussy in details. Never be long-winded without very good reason. 6.1.6 Data Data presentation is an art itself and should be carefully thought out and discussed with mentors, as it is the core of the manuscript. Again, the key is good communication, so if a table or graph does not help the interpretation (i.e., if it does not bring out the feature of interest) then it should be changed. However, high impact always trumps fancy presentation, so a boring bar graph is often good enough if it makes a simple point. Data tables have the advantage of range and completeness of data presented, but is more accepted in some fields than others. Where complex data does not inform it is often best to move it out of the way to a supplementary data section accessible to those interested. 6.1.7 Repetition Repetition (with rephrasing) is a useful writing tool in manuscripts, where a major topic or factor is introduced, then discussed, then a conclusion is reached with it. Nevertheless, repetition must not be overused, so points and arguments that are not central to the enterprise should not be repeated. 6.1.8 Be mindful of who will review it Any manuscript will be reviewed by a peer or editor of the journal. Experience here is really a key, so help is needed from someone who has it. Answering reviewer critiques is an art in itself which takes time, much suffering and good anger management. Key points to remember with reviewer replies are to be unfailingly polite, answer questions directly and do not take too much nonsense even if you have to courteously pretend that the reviewer is not a complete clown. 6.1.9 Publication and manuscript submission This is a complex process and always takes much longer than you think. Always rigidly adhere to the journal Guide for Authors regarding subject scope, length, structure and formatting. A letter to the editor is required to explain why they should publish your work, and this should be taken seriously. 6.1.10 The pat on the back If your manuscript is accepted for publication, well done. It is no mean feat even for a small paper. 6.2 Manuscript publication and authorships This is a brief guide to the issues and etiquette around developing and publishing manuscripts. Preparing a manuscript for publication is always arduous, and involves a long period (usually underestimated) of manuscript development, followed by the journal submission process and peer review, none of which are trivial matters. 6.2.1 Authorship As a rule anyone who contributed to the form and content of a manuscript should be included as an author. Most journals have a guide as to who should and who should not be included in the author list. An author should make a contribution to one or more of the following necessary features of the manuscript: its conceptual development; contribution of important materials needed in the study; the data generation or collection; manuscript writing; figure composition; and critical discussion or editing. Clearly there are grey areas, such as whether technical help is acknowledged, however, contributing only patients to a study, or providing some minor material contribution is not sufficient. On the other hand leaving out a significant contributor to the manuscript is a type of misconduct and potentially serious. It is a good idea to clarify to all authors at an early stage that they will be included. Signatures or some other sign of assent of all authors may be required for manuscript submission to a journal, which should be borne in mind if there are any co-authors that are hard to contact. 6.2.2 Author list There are various conventions for authorship order but in biomedical publications the writer of the manuscript and main driver of the project is almost always first author. A newer convention of biomedical publications is that the last author is the senior member of the team and has made crucial, project-enabling contributions. Note that in other fields (e.g., bioinformatics and chemistry) these conventions may be very different. The corresponding author for purposes of manuscript submission is also a significant status and is often the senior author but can be the first author, but must be an author willing to deal with the submission itself. First, senior and corresponding authorships may be multiple, i.e., more than one joint first author or senior author, which is an important convention when the study is a collaboration across groups. 6.2.3 Manuscript structure This varies but almost always includes a front or title page, abstract (150 to 300 words), Introduction (which includes a review of the research area and literature), Materials and Methods, Results (structured description of data) and Discussion section (describing how the data aligns with current literature). The specific details of these must follow the guidelines for the intended journal. The text should contain relevant references that support major statements and assertions in the text, and these should be included in a list after the Discussion; then there are the figures and tables and their respective legends that detail the data. Note that some extra data and other information not included in the main text (e.g., negative results or extra analyses) may be put into supplementary figure for most journals. Ideally all the format of text (especially word number of respective sections) and figures should conform to the intended journal, and it saves time and effort if this is done from an early stage. Adhere rigidly to journal requirements for manuscript, figure and table formats and conventions. 6.2.4 Developing the manuscript Usually one or two authors take main responsibility of the writing, and it is absolutely essential to get critical input at all stages of development. It should be agreed early how to distribute writing duties and how the manuscript will be distributed for critiques. At the start it is usually best to circulate MS Word documents that can be used to track changes, because structural changes and rearrangements to the text are often needed. Version control is crucial and will drive everyone mad if this is not done properly. A good convention is to adopt one version as the master draft, and to pass this to a co-author for editing and prompt return; during this time no alterations by anyone else should be made. A version number is important in the header and filename to avoid confusion. If these points are not adhered to there is a risk of developing parallel incompatible copies. Later, when the structure is clearer but writing amendments and checks still needed, it is better to use an online resource such as Overleaf or Google docs that allow simultaneous editing. When only minor checks are needed at the end, then make sure the drafts are approved by all authors. 6.2.5 Writing Do not be precious about your writing; gracefully accept criticism and edits. Have a story that pulls all your main ideas together will help text flow and clarity. Write clearly and check with others that it is indeed clear and understandable. Minimise complex sentences, aim for only two lines (three at most) per sentence. Link paragraphs. Use clear and informative figures and tables. Use diagrams where possible. Make the conclusions sound strong and important, but note important caveats. Remember you know the subject better than most, so do not assume everyone understands your arcane terminology and arguments. Recognise most people do not produce their best writing on first draft, and it needs critiques from others to improve it. Spend as much time as possible going over the drafts repeatedly. Remember the oft-quoted “Easy reading makes hard writing” [Thomas Hood, The Atheneaeum, 1837]; it is always true. Manuscripts that read well and have a compelling argument or story will far more easily get past editors compared to those that are not. You want to be proud of your manuscript when it is print, but there is no short cuts in the time and effort to get it right. 6.2.6 Dealing with data Like the writing drafts it is important that the data being used is kept up to date and accessible which may not be simple if it comes from multiple sources. The datasets should be regarded in a sense as part of the manuscript, and care take accordingly. For primary data most journals now require that raw data is publicly accessible in some form, usually in an online repository. 6.2.7 Public access to the published manuscript Many grant-giving bodies mandate early or immediate public access to manuscripts, either via journal website or a public repository. Check the journal instructions for authors how this can be managed and how much this will cost. Bear in mind the copyright may have to be assigned to the publisher. Manuscript publication is a hard job and you never stop learning. Remember also that writing will always help you refine your understanding and your expertise. For that alone it can be worth the pain, or at least some of the pain. 6.3 How to collaborate on writing manuscripts. Publishing a manuscript is a complex process needing a lot of work and much input from collaborators. If this not handled and organised well this hard but manageable task can become a quagmire of floundering conflict and confusion. To avoid this, there are important points to consider. Journal publications are the main avenue for communicating scientific evidence and ideas, and they demonstrate the authors’ contributions to the scientific corpus. That is why publication metrics are used as productivity indicators in grants, awards and job interviews, so authorship on paper is a big issue. Collaboration is essential for manuscripts to see the light of day (evidenced by the extreme rarity of single author research publications) so this must be managed well. 6.3.1 First stage of manuscript development: shaping the idea and getting the data When starting out with an idea for a manuscript, working with collaborators and colleagues is useful to review and discuss the literature, as well as assess and extend any data. Manuscript co-authors become evident from this process, as it is crucial to properly acknowledge contributions to the paper. It is then necessary to decide who should be first (or joint first) authors and senior authors. 6.3.2 Authorship status First authors are the main drivers of the project and manuscript writing, while last authors are those with senior status overseeing the project. Clarity about each author status and contribution is important. Sometimes at a later stage the contribution one author may increase to the point they can be justified to be first authors, but it is hard to go back on undertakings to the original first author, so this must be handled sensitively; joint first (or joint senior) authorship can be a good solution. 6.3.3 Second stage of manuscript development: presenting the work and preparing figures Data analyses need to be assembled in figures and text to present at oral and poster presentations. These are great for practicing figure construction and writing, to test out the narrative structure and to get critical feedback. Indeed, the best feedback may well be from collaborators who can now see the project taking form, so a copy of any poster or slides should be sent to all of them beforehand with enough time to provide comment. It is also a courtesy, as it demonstrates they are involved and that their input is appreciated. Bear in mind that authorship lists on conference presentations will create expectations for author inclusions and author list order in the related manuscript. 6.3.4 Drafting a manuscript It is usual that text and figures are worked on by one or two authors with critical reading by other authors. Version control is crucial, as without it there is a confusion of parallel draft alterations, plus the nasty risk of contributors amending out-of-date drafts, which will deeply annoy them. For early drafts, e-mailing (MS Word) copies of drafts for co-authors to make tracked changes is good, but there are also good online options such Google Docs or Overleaf.com that allow simultaneous editing. It is best not to perform major surgery on a draft while others are working on it, so this should be managed carefully. Among around manuscript development issues, a thorny one can be deciding which points should be put in the Introduction and which in the Discussion section. 6.3.5 Authorship etiquette in manuscript writing It should go without saying that the main manuscript author should treat other co-authors with proper consideration. This includes clarity over their roles, and treating their edits and amendments seriously. Requests for input from other authors should give them time to respond before deadlines; an unexpected request sent late on Friday for a Monday morning deadline is not respectful. It is also important to actively acknowledge the contributions of particular authors that have put in effort. It is nearly always difficult for inexperienced writers to accept criticism without being defensive. After working long and hard the new writer gets emotionally attached to their creation. Experienced writers know a near-Buddhist lack of attachment is best, as you may need to sacrifice your favourites for the greater good. There is also the Dunning-Kruger Effect which, paraphrased for the context, is that inexperienced writers have yet to learn enough about writing to understand just how awful their scientific prose really is. A trusted mentor, or a senior colleague whose irate opinions cannot be ignored are usually the only fix for this. As a major point of etiquette, do not plagiarise others. It is always unacceptable, easily detectable and, hence, always embarrassing. However, it may be reasonable take a short piece of text by a good writer to recast later in your own words. With manuscript done, always get permission from all authors before journal submission; failing to do this really is a cardinal sin. Usually a first or last author is designated ‘Corresponding Author’ and performs journal contact tasks; note in some circles, being corresponding author carries extra status. 6.3.6 Research ethics and collaborators This is a huge subject, summarised thus: be honest, be open, be scrupulous and always do things in good faith. Do not cut corners on this. Make sure data and data analysis is correct and get it checked by others. If you suspect the ethics of a co-author or data supplied by them, seek mentor advice before the problem snowballs. If something is wrong do not delay to deal with it. Make certain of ethics committee approval for the work – ethics approval numbers will be needed for journal submission. 6.3.7 Third stage of manuscript preparation: finalising the manuscript Once structure, narrative and data is done at last, finalising it all in a publishable draft can be surprisingly long-winded. Almost everyone (even those most experienced) underestimate this, often hugely. This is due to the need to inspect the work from every angle, and it is common to find major data issues only with writing underway, e.g., a vital control group not included, or a minor section that has become major starts to wilt under the increased scrutiny. Get co-authors to help with this process, as extra brainpower is needed to spot problems before peer-reviewers do. Do not submit a manuscript without appropriate input from all others thinking that the journal reviewer will provide the appropriate suggestions; that approach never ends well. Read, read and read again the manuscript and do not be afraid to make changes even in the underlying principle to make the writing clear and concise. Be brave and delete words or paragraphs that do not clearly add value. 6.3.8 Fourth stage of manuscript preparation: the fiddly bits at the end So many fine details and minor features (including formatting for journals) need to be finalised for journal submission that it inevitably takes far more time than seems reasonable. It is not hard but here, alas, the first author is usually on his or her own. 6.3.9 The peer review process This is not an easy process to navigate, so co-author help is needed at all stages, and it is essential get their approval before a response to peer review is submitted. Take peer review criticism well and courteously. Provide any further data that is requested or provide good reasons why not, for example, if it would give uninterpretable results or is outside the manuscript scope. This is a delicate craft requiring experience and good advice. It is generally understood that a journal editor will accept the manuscript if the authors properly respond to the points raised by the reviewers. A second review by the same reviewers is needed to confirm this, and it is a convention to help preserve everyone’s sanity that the second (i.e., last) review will not raise substantive issues the first did not, as it allows no possibility for response. This is not always true of the highest journals, however, who do as they see fit, because they can. 6.3.10 Money Do not forget most journals charge publication fees, so make sure the appropriate funds are secured before submission. 6.4 Producing the first draft of a research manuscript Here we go through the steps of developing a piece of research work for publication in a reputable journal, and some time tested strategies. 6.4.1 Starting on the blank page Before the first text keys are tapped, the findings of the data analysis should be very carefully examined, and how the proposed paper might fits with other published work in the area thoughtfully considered. Note the data serves the paper and not the other way round - some data and analysis may, in the end, be left out. The main points, arguments and conclusions can then be summarised in bullet form. It is a useful thinking aid to place these points in order priority and importance, and evaluated as to which must be in the paper and which are less essential. 6.4.2 Journal choice and information on format It saves time later if the formatting of the manuscript is right from an early stage, so it is good to choose a target journal, then consult and adhere to their “Instructions for Authors”. Then it is good to start to write out formatted section headings, and add the above dot points where appropriate. Thus, a document is produced with a Front page (title, names, affiliations), Introduction or Background, Patients and Methods, Results, Discussion, References, all ready to be fleshed out. The document should from the beginning look like a proper and neatly crafted manuscript. The authors will then see a real paper emerging in front of them, giving the enterprise some feeling of momentum gained. 6.4.3 Assembling the data As soon as possible key data should be assembled in a presentable and finalised (or near final) form. The conclusions that form the basis of the paper can then be written in a short, direct way with a minimum of hedging, fudging or caveats. Everything will then rest on how well the data will buttress those conclusions. It is often useful to draught out (on a whiteboard perhaps) a layout of the figures, tables and diagrams to work out the best sequence they should appear in. This process constructs the manuscript narrative, and it needs to be discussed in detail with the other main authors and mentors. Note that having a rich array of data and methodologies (even if some is later relegated to the Supplementary sections to save space) helps to impress editors and inspire confidence in the work. At this stage it should become evident if there are any significant data or information missing, but if all the essential data is in place then text development can proceed. If it is not, there is a risk that new data arrives that radically changes the manuscript. 6.4.4 Writing up Results and Figures After the general outline has been envisaged, it is usually best to put together a rough version of the Results section based on the figures drafted above. A logical sequence of Results section subheadings, fleshed out with concise descriptive text is needed. It starts with plain but scene-setting data and data that confirms the work of others. Good figure/table/diagram legends should be written at this point, using the journal conventions. 6.4.5 Introducing everything The paper scope should be evident at this point, so work on the Introduction should start; it may take time to develop since consulting the literature often throws up unexpected challenges. This section starts with general statements about the field or clinical problem, noting particular and peculiar features (including its importance of the field and the challenges it presents) which expand into a solid but short review of the field that highlights key knowledge and areas of ignorance. It will display a firm grasp of the subject and make clear what knowledge gaps the manuscript will fill, and lead the reader logically to the work presented in the manuscript. The Introduction should mention the research approach employed and why it was chosen. 6.4.6 Methodical with Methods Writing the Methods section is always useful as it involves a lot of formulaic sections (e.g., details of ethics approval, statistical approaches) that are easy to write but take time. There must be enough method detail presented to support the technical credibility of the paper. 6.4.7 Discussion among friends The next part to tackle is the Discussion section which should be developed slowly with many revisions, as this helps the logical development of the paper. The section should begin with a brief summary of the most important Results, then a section that carefully considers how the results of the study do (or do not) support the project aims and hypotheses. This should merge into discussion of the major literature on the subject and how the study fits with this. The Discussion should clarify the limitations of the study, and what future work it might lead to. The section should close with a statement of conclusions of the study that does not just restate the Results yet again, but brings out the key messages that emerge from the Discussion. 6.4.8 The next steps: Abstract and referencing The work completed up to this point should enable the construction of the Abstract. This requires a whole set of writing skills in itself as there is nothing quite like it in style, but its structure and content has to accurately reflect the manuscript Introduction, Methods, Results and Discussion substance, hence why it is best left until these sections are at least drafted. The Abstract begins with a terse description of the problem and state of the field and ends with the conclusions. In between, there is the narrative sequence of arguments and information. Reducing abstract length and stripping it to essentials is needed and must be ruthless as word limits in journals are rigid. If it is too long, leave it aside for a while in order to view later with fresh eyes. There should now also be proper referencing that supports points raised in the text. This requires obsessive and careful literature consultation. A neat way to evade immediate tangles with reference manager software at this stage is to insert citations in the text as simple PubMed ID numbers. These can easily and rapidly replaced with the proper format in later drafts. 6.4.9 End of the first draft The development of the manuscript to this point probably involved collaboration between authors, but if not then it must begin here. A choice of document sharing strategy must be made – will the text be circulated as MS Word and PowerPoint documents, or online shared documents such as GoogleDocs or Overleaf? Whatever is decided, version control is crucial to avoid time-consuming blunders made like editing old or out of date drafts. Thus, it is best to be clear which file is the ‘master’ or definitive version, with only one person editing it so confusion is avoided. However, online document tools (such as GoogleDocs) can allow simultaneous editing by more than one author which can get round this problem. Whichever system is used, tracking document changes is very helpful as they make amendments visible for all the authors to consider. 6.4.10 Onwards With completion of a first draft much has been achieved but much remains to be done. This will take time and it is important not to underestimate this. This is scientific writing, and while it needs to be succinct and pointed it should also read well to maximise the chance the reviewers and editors will accept it for publication. The draft needs persistence to ensure the narrative and messages are clear and eradicate unnecessary adjectives, adverbs or notions that do not contribute to the main themes of the paper. “Hard writing makes easy reading, while easy writing makes hard reading” (Attr. to Thomas Hood)* 6.5 Manuscript citations A prominent feature of a scientific manuscript is the care with which citations have been added to the text. Any assertion made in the text is linked to a source of evidence (hopefully solid evidence) that supports that assertion. In any manuscript intended for publication this must be done well and thoroughly, so here we discuss the ins and outs of how to ensure this is achieved. 6.5.1 What is a citation? This is a reference to a previously published work that is commonly accessible. In the pre-internet age of distant memory such ‘access’ often meant long waits for printed copies (or photocopies) of the work to be arrive, but access blocks due to internet paywalls are the main barriers now. Most citations refer to journal articles and (less commonly) to book chapters and conference proceedings. The detail of a reference itself is usually quite long, so it is placed at the end of the manuscript with a link at the text location where it is invoked. In this way a reader seeing a contentious claim in the text should be able to locate the supporting evidence with a minimum of fuss. The work referenced may be a primary publication, i.e., a full original research article, an essay, a literature review or, on occasion, a published abstract. Peer-reviewed articles from a respected source are always preferred but a citation may from necessity refer to a grey literature item, such as non-peer reviewed internal reports and policy papers. 6.5.2 Where are citations needed? Any assertion of fact in a manuscript needs to be referenced to a source that supports the assertion. Citations need to be inserted either next to the assertion in the text or at the end of the sentence; unreferenced assertions are frowned upon unless the assertion is accepted as common knowledge. Where a good reference cannot be found to back a claim, the claim should either be excised or appear with a remark about its lack of substantiation. Where a very general claim is being made, or the claim involves a lot of detailed papers, then citing a literature reviews provide a good shortcut and (an important consideration) it helps keep down the length of the manuscript reference list. However, citations of literature reviews should not be over-used, and the reviews themselves should be checked that they are appropriate. 6.5.3 What form does a citation take? Usually there is an abbreviated reference, often a reference number, which can be looked up in a list of references at the end of the manuscript. Within the text the reference number can be a superscript or in brackets; alternatively, it may be in the form of first author name plus “et al.” (if there is more than one author) plus a publication year all placed in brackets, but this appears to be becoming less common. Note “et al.” is universally employed to mean ‘and others’, but it is a Latin abbreviation (et alii/aliae depending on gender) so italics and a full stop are the convention. The in-text format and the references list format used for the manuscript depends on the preferences of the intended journal, which can vary widely, so the journal “Instructions to Authors” needs consulting. 6.5.4 Checking references It is important not to use an inappropriate reference, so cited papers need checking with care, i.e., the referenced paper (or at least its abstract) should be read. It can be dangerous to rely on a paper title alone to indicate its content, although for very obscure or old papers there may be little alternative. The details citation itself must also be accurate, which is not difficult to ensure with digital resources. 6.5.5 How to find sources to cite It is useful for citations to be inserted into the text while the text is written, because if an assertion of fact is made which later becomes central to the manuscript narrative then it will cause embarrassing problems later if the source cannot be found. Virtually all journal publications should be accessible at the NBCI PubMed resource1 which accesses the Medline bibliographic database, and careful and wide-ranging searches should be undertaken. Note that the unique Pubmed ID number (PMID) for a publications is a fairly foolproof way to locate the reference later on unless the reference is outside the biomedical field. Outside of the main biomedical literature there are also commercial databases like Web of Science, Scopus and Proquest which have their own conventions. 6.5.6 Deciding which publications to cite There are no certain rules on deciding appropriateness of a citation, but there are some expectations and rules of thumb. A general statements is often best supported published reviews, while a specific statement is best supported by a citation (or two) of research papers that directly provide support, preferably declared in their abstract. To avoid excessive citations some journals encourage using published review citations more liberally, even though this is often not ideal. An obscure or doubtful publication should not be chosen over a more reputable one, and here consulting published reviews to identify the seminal papers is useful. Withdrawn publications should not be cited. Where no citation can be identified this may indicate a knowledge gap that could be commented on. 6.5.7 Inserting citations into text Putting references into text can be a fiddle since the software that does it tends to be clunky. Until recently the most common types of reference manager software were proprietary programs such as Reference Manager (discontinued 2015; Thompson Reuters), SciRef (now version 1.5; Scientific Programs) and EndNote (now version X9; Clarivate Analytics) that search for and download PubMed data then link it directly to text in MS Word documents. There are now alternative managers available, and some free are free. such as Zotero (New Media). LaTex publishers (usually free or freemium model) such as Overleaf.com enable insertion and formatting of in-text and end-text references using a coding approach. These are increasingly useful as they can take in records and format that can be obtained with minimal hassle from PubMed. 6.5.8 Formatting of reference lists Reference formatting has always been a nuisance since there are so many ways that journals can cite articles. For any manuscripts the instructions to authors should be consulted and followed carefully. Templates for particular journals are often available in reference manager software, however these are occasionally wrong so should be checked that their output looks like what appears in the target journal. A common type of reference list is the so-called Harvard System but, annoyingly, no definitive standard for this system exists; for journals a typical format is Author list (in comma separated surname - first name – initials order), year, article title, journal title, volume, issue, page number and DOI. Citation conventions can be quickly grasped and become second nature when writing documents, so becomes hard to write a document without at least one reference. www.ncbi.nlm.nih.gov/pubmed 6.6 Writing manuscripts abstracts – one of the hardest writing skills All manuscripts need an abstract or summary, usually 300 words long, and after publication it is the abstract that an interested reader will first engage with the work. Journals care a lot about abstracts, not least because they care about citations, and a badly written abstract will repel potential readers who might otherwise cite the work. Authors themselves similarly care a great deal about having a well written abstract that shows their work in a good light, so abstract writing is an important skill to develop. The biggest problem faced by an abstract writer is usually that it is hard to shoehorn a lot of information into 300 words and keep it coherent and readable. With this in mind, below are some approaches to write manuscript abstracts as well as conference abstracts, which are only a little different. 6.6.1 Starting out An abstract is in effect a fully self-contained document, so can be read without reference to anything else. A special effort should be made to make sure that the pre-amble and the conclusions at the end are as clear and simple as possible, as these are often the parts that readers go to first and will remember and which will frame the other more technical parts. The introductions and conclusions of an abstract should use concrete and precise statements, and not include vague language or include wildly overoptimistic claims. 6.6.2 Obey the abstract constraints The first task is to identify the abstract word or character limit and to stick with it. If it is to be submitted online it is often the case that the limit will be enforced automatically by the submission portal. If there are other constraints, note them. One to look out for is whether the structure is mandated, e.g., it prescribes a labelled Introduction, Methods, Results and Conclusion sections. Do what is asked, or risk rejection or, at the very least, instructions to rewrite. 6.6.3 Conference abstracts Conference abstracts differ from those in manuscripts in that they are written from scratch well before much of the project presentation is prepared, while manuscript or report abstracts summarise and are part of a relatively mature document. The conference abstract is written to appeal to the committees and attendees of a conference that lies some time in the future, sometimes after more work will be completed. To avoid regret it is crucial that any result reported in the abstract is already obtained, done and dusted at the time of submission, and not merely anticipated to come in future, tempting though that may often be. If possible include some illuminating summary statistics in the abstract. The following is one fairly common approach to constructing a summary abstract which can work when the abstract length is very constrained. 6.6.4 Stage 1: assembling the pieces. This is done more or less backwards, with the conclusion written first. This may be an expanded and more precise version of the manuscript or presentation title. Bearing that in mind, the next thing is to write out in rough dot point form what study results need to be included to buttress that conclusion. Do not include anything that does not contribute to the impact or which cannot be explained well in concise terms. Next, list the methods and clinical information needed for the results text to make sense, although specific method details can usually be abbreviated as in, for example, “a systematic review was performed”. A preamble that places the study in its context and makes it clear why the study was done (and why it is important) can then be added at the top of the abstract. Finally, at the end of the conclusion a short sentence might be added explaining briefly what it the conclusions mean or imply in the clinic. It does not matter if the abstract is over-size at this stage, as it is important to make sure important material is included. Then the abstract will need to undergo a series gradual (but often painful) reductions. 6.6.5 The first amputations The abstract first is examined carefully for significant omissions and for any text that could, on mature reflection, be left out. The abstract length should be compared to its required length to get a good idea of the level of discomfort ahead. Any loose phrasing such as “in general it was observed” or “there is a great deal of evidence that” can be slashed. The introduction can also be truncated if it is clear that the audience is an informed one. Then it is usually best to leave the whole thing aside for a while, a few hours at least, but a couple of days if possible. 6.6.6 Stage 2 – the cycle of text reduction When returning to the abstract it will be clear that there are sections that can be excised or revised to shorten. It is often best (where possible) to go through a few rounds of cutting followed by a rest of a day or so before returning to the job. However, as the options narrow it can be necessary to recast long sentences to carefully shave off a few words here, an adjective or stray comment there. As the density increases it really helps to have a strong grasp of the language, so if English is not your native language then get some help. Cycle by cycle the abstract size will reduce as originally prized turns of phrase or nice but bulky explanations are sadly jettisoned. 6.6.7 Stage 3 – the unsuspected cruelty of other people When you can do no more, but still the length is excessive then it is time to use the eyes of an objective colleague or mentor. You may be emotionally attached to your text, but they are not. They come to it afresh and will not hesitate to suggest cuts or restructures. 6.6.8 Stage 4 – discussing with the co-authors. When the abstract is a reasonable length and in a good state it should be shown, ideally with the rest of the manuscript, to the other co-authors for their feedback on the content. If they are engaged they will suggest new perspectives and highlight issues, but hopefully not too much if deadlines are short. Indeed, it is often useful to be clear about a deadline for responses in the email used to circulate the abstract text to avoid hold-ups. 6.7 Writing a manuscript introduction A research manuscript Abstract summarises and advertises the study, its Results section, (with its figures and tables) catalogue what the study found, the Methods section how it was found and the Discussion and Conclusions explain what it all means. The Introduction section connects all these, and provides an entry point for the critical reader looking for details of the study itself. It provides a brief summary of current knowledge as well as knowledge gaps in the field, and gently leads the reader towards the questions the manuscript is addressing. It may also give a few pointers to the research approach used. Here are some general pointers on how to construct a good Introduction section. 6.7.1 Starting out – writing and thinking When starting to write the Introduction some outcome data and method details should to be in place to help guide the writing. Nevertheless, it is a good idea to write an Introduction draft as soon as possible as this both helps give a concrete shape to the emerging manuscript and practices the arguments and narrative that will be used. 6.7.2 The scope of the manuscript, It is important to be clear about the scope of the manuscript and how general or focussed its subject when writing the Introduction. There is little point in writing much on subjects that the manuscript does not address, as this will only distract and irritate the reader. Thus, for example, introducing a study on an HIV infection prevention strategy will not require an extended essay on AIDS (unless the audience is somehow unaware of AIDS) but rather a brief summary of the relevant features of HIV infections with an overview of current prevention strategies. 6.7.3 Style The Introduction provides an opportunity to write plainly as it does not have to be as dense as the Abstract nor as dry and detail-focussed as the Results and Methods. However, every sentence should justify the space it takes up, should be short and should be carefully linked to other sentences to make the text flow well. Most journals have word length limits (which should be checked) and readers have their limits too. A short, clear and informative Introduction that is stimulating and easy to read is the general aim, which will not only encourage the reader to continue through the manuscript but also persuade even difficult editors that the manuscript should be taken seriously. Achieving all this takes time and many revisions with input and polish from other authors. 6.7.4 Models If there are other papers close in subject matter it is always useful to see how they have written their Introductions. These should be carefully examined to identify features that would be a model to emulate though, of course, not emulated too closely. Those papers should in any case be read to provide clarity about the current state of the field, and to help crafting the manuscript to bring out its novel and important aspects, emphases that should be prominent in the Introduction. 6.7.5 Preambling The very first part of the Introduction should be a preamble sentence or two that raises the general topic that the manuscript will address. This is needed so that the reader can immediately engage with the subject and judge its relevance to them. The necessary brevity of the preamble means it can do little more than state why a disease or condition urgently requires our concern, and what has previously been done to address it. This sets the stage for the next part. 6.7.6 Overview or background of the subject This part is a mini-review of the subject area, with appropriate references. This outlines what is known of the pathobiology of the condition and its important clinical features. This section forms a substantial part of the Introduction, more than half, and should be useful to any readers interested in the field rather than in your work. Indeed, if there are no narrative reviews on a subject then reading the Introduction sections of papers in the field can be the next best thing. However, this mini-review should not contain excessive detail beyond that needed to comprehend the study and its outcomes. Hopefully, the reader will become better informed, and confident that the subject is important and that authors have a firm grasp of it. 6.7.7 Leading into the rest of the manuscript: why was the work done? Next to include are the important questions that remain in the field, and specifically what questions the study addressed. That research question, decided when the study was originally designed, is usually summarised succinctly in this part, although in some cases it may be better to put in the preamble. There should be a note regarding why the particular approaches or methods used were employed; this can be an opportunity to head off reviewer arguments that another approach would be better. The research hypotheses may be stated here, unless the manuscript is exploratory rather than hypothesis-driven, in which case the research strategy needs to be outlined. 6.7.8 The ending Lastly, the last few lines of the Introduction should note the intended outcomes of the study. Alternatively, the main actual outcomes of the study could be mentioned. Choosing which alternative will depend on the journal targeted, which should be examined to find its preferences. 6.7.9 Introduction versus Discussion Included in the Introduction will be a lot of material on the background of the study but this may end up making the Introduction too large. One solution is to move some of it to the Discussion section, where there is more space and it can enlighten debate around the study findings. It can indeed be hard to decide what to put in the Introduction and what in the Discussion and neither option may be perfect. Whichever is decided, the priority is that the Introduction is short, well structured and does not ramble on about peripheral subjects. Some text may have to be moved or removed to achieve that, and some imperfections are inevitable. 6.8 Writing the Discussion section of a manuscript. After the scene has been set in the manuscript Introduction, the data that supports the manuscript is detailed in the Methods, Results and the figures. The Discussion section is last on the list to compose. It is often viewed as the dull anticlimax at the end, but in fact it is a very important part and has its own peculiar requirements. Here we discuss writing it. It is true that the Discussion section is probably the least consulted part of the manuscript because to fully appreciate it requires a deep knowledge of the subject that not all readers have. An important exception will be peer reviewers, who will read it very carefully. Ideally they will find the strengths of the study are made clear and any apparent problems with the data interpretation addressed in a scholarly way. Thus, even if it is a little arcane the Discussion must be good. There are manuscripts where the data more or less speaks for itself, but even there the Discussion must pass muster. It is in the Discussion section that the outcomes of the manuscript are linked clearly to the current state of knowledge about the phenomenon of interest. There also the data (and its interpretation) should be subjected to withering critique, yet shown to remain standing if perhaps quivering a little. The Discussion also includes writing about other relevant studies of the subject; here, there is sometimes an opportunity to have a little fun (but only a little) by critically evaluating the work of other groups. 6.8.1 The most common mistake A frequent flaw in Discussion sections is to simply recapitulate the Results. That obviously does not add value, so if the Discussion section reads like a re-run of the Results section then it is bad, as the reviewers will usually indicate. A brief summarising of the main Results is usually needed, but that is all. A Discussion section differs quite fundamentally from a Results section because it is discusses (the clue is in the name) while conversely, the Results section should contain relatively little discussion of outcomes, enough only to link the parts of the Results section fluidly. 6.8.2 The first part of a Discussion section Thus, for the Discussion section to draw together the themes raised in the manuscript, and link it to current state of knowledge, a brief recapitulation of the main study results is needed. This should be concise, fluent and limited to the points to be discussed. This summarization usually occupies the first paragraph or two. Alternatively it may be mixed with other elements and dispersed through the Discussion section, a style used when results naturally fall into distinct parts that need their own discussion. 6.8.3 After summarizing the Results talk about what they mean and how good or bad they are. This is mainly what a Discussion section is for. The Results should be discussed in terms of their reliability, strengths and weaknesses and contrasted with other published work. This mulling over of the Results should raise key features and conclusions of the work, the most important of which will also appear in the abstract. 6.8.4 The Discussion section should contain some support for a thesis A thesis, or proposition, is usually the focus of a paper, unless the paper is purely descriptive in nature. The Discussion will put forward that thesis and examine how it is supported by the study results (and other peoples studies), rather than simply displaying learning and erudition or showcasing a lot of all the hard work. The Discussion is where the ideas underlying the study will emerge based on what survives criticism. The tone should be disinterested, and display a real sense of curiosity and interest in what the outcomes might mean. 6.8.5 Explain what should be done to fix particular weaknesses in the paper It is important not just to expose the weaknesses of the paper but to try to fix them as much as it can be done. Where there is a remedy for a particular weakness (e.g., do a bigger study) it must be clear that this is beyond the scope of the manuscript. If you mention a simple or easy fix for a perceived flaw in the manuscript you will probably be asked to fix it before publication so careful thought is needed round this issue. If the fix is not so simple, it should be explained why. 6.8.6 Linking the work to the wider literature How does the data relate to what others have seen? Has it reproduced the observations of others? All the relevant literature must be cited, unless it is very extensive in which case cite the main studies and reviews. 6.8.7 The Conclusion In some journals the conclusion is a separate section, if not it will be the last paragraph or two of the Discussion. It should briefly mention again the main problem or question that the study set out to address, the main features of the Results and what was concluded from these in the light of the current body of knowledge. After that there is only a wrapping up sentence, perhaps a peroration or high point that inspires enthusiasm for the work, summarizing what it means and what it points to for future studies. 6.9 Performing a journal peer review It is a great idea to perform journal peer reviews as it is an excellent way to hone skills of criticism and argument, get a better grip on the subject and gain some recognition with the journal. Lack of previous experience should not deter, but there are some considerations before accepting the responsibility. The first consideration time and timeliness – most reviews must be done within in a 10 or 14 day period, though journals may allow more time if asked. The work burden is significant, and can take several hours, so it is essential that it is possible to do it in the time available. It is not fair to the authors if the report is very late and it is best to be frank about this with the editor. It is never a good idea to accept to do too many peer reviews proposal exactly for this reason. The second consideration is expertise in the subject are – do you have enough to do the review? The third consideration is support – is there somebody experienced who can advise or help on the review? 6.9.1 What is peer review for? Articles for publication need to ensure the quality of the publication. It is not expected to be, nor can it be, a perfect process. It can only be considered an important filter of quality. It is not the last word on the quality of the publication although unfortunately careers can be affected by the outcome of a manuscript review, especially in higher impact journals. Peer review can be subverted and gamed, but is still recognized as essential. 6.9.2 Who does peer reviews? Anyone who has a publication record in the area may be chased to do a peer review. Reputation for expertise counts, which can mean that senior scientists and clinicians are asked a lot. Thus a senior clinician who cannot perform the review will often nominate a junior colleague or student. This is where most people get their first chance to review and it is an expression of confidence that the junior person can do it. Note also that usually peer review is anonymous to the manuscript writers. 6.9.3 How is a peer review used by a journal? Journal editors want to know if the manuscript is worth publishing, whether it needs significant or minor revision, or whether should be rejected. The two key points needed to accept a manuscript (with or without revision) for an original research work is that the subject comes within the scope of the journal (a decision more for the editor) and that the data supports the conclusions. Other important considerations include how well the manuscript is written and that the data look plausible, if it is capable of replication (in principle) by others, and is free of any fraud or other dishonesty. 6.9.4 Can opinions about the manuscript be direct or is deference needed? A peer review should make direct statements about the details and execution of the study and the manuscript, but it is essential to be polite and not aggressively negative or mocking. Reviews should be supportive to the authors as far as possible and phrased with kindness, consideration and, if merited, gentle diplomacy. Advice should be given where it is clearly needed. 6.9.5 What happens if evidence and data are incomplete in the manuscript? Be circumspect about asking for more data, where it would be hard for the authors to comply. However, if the evidence as presented fails to support the conclusions then it is a central point that must be raised. If the authors cannot comply or amended by the authors the paper must be recommended to be rejected. The authors will have a right of reply and an opportunity to revise the writing and add data if they wish. Note that if there is some data that might improve the manuscript but is not essential, the convention is to ask the authors if they can add it, rather than demanding that they must supply it. 6.9.6 What is the process of undertaking the review? Best is to read the manuscript thoroughly, abstract first then tables and figures, the key parts of the paper upon which it will stand or fall. Scrutiny of data quality and statistical analysis is crucial and expertise is needed. Then the rest of the paper should be assessed. Notes should be made on every important point, and any perceived flaws. Other relevant literature should be checked (briefly) so manuscript consistencies and differences with other published work noted. Then the review report can be drafted. 6.9.7 What about errors in the text? Serious problems in the manuscript reasoning should be noted. Problems with language or typos should be mentioned in the report without necessarily listing every example. Comment in the report on clarity and the standard of English, but a manuscript should not be rejected solely because the language needs work unless it is truly impenetrable. 6.9.8 What sort of reports need to be submitted? There are typically three parts to the report. There are accessory questions (usually drop-down menus) such as whether the statistical analysis or the conclusions are sound. Then there is a main detailed report for the authors (and editors) to read. Lastly is a direct report to the editors, which the authors do not see. There will also be options to choose recommendation of manuscript acceptance, revision or rejection. 6.9.9 How to write the report? For the main report to the authors, there are no hard rules and some people just state very few bald points. However one good approach is to start by briefly describing in one sentence what the paper is about (some reviewers write whole sections on this), then say one or two positive things about it, and state if the study is sound or not. Indicate how clearly the paper is written, how well the conclusions are supported and how important the study outcome is. Then, usually, comes the “However…” statement – the most important concerns about the paper. Then list as dot points each major detail that the authors must address to get the paper acceptable to you, lasts minor points and typos. If there are no major points then the paper presumably can be accepted with minor revision, or is so hopeless it must be rejected. Note that the latter are quick to review. Review reports can be long but it is best under a page. Note there may be specific things to raise, such as the declaration of ethical approval, study preregistration and others, but that depends on the type of study the manuscript describes. The last task is the statement to the editor. This is not seen by the authors is best brutally frank and open on the merits or demerits of the paper and what it would take for the paper to be acceptable. This should be brief (the main points are made in the other report), just a few lines. 6.9.10 What happens next? If the editor decides that the manuscript has merit the authors will be invited to submit a revised version. You will be asked to review this. Your sole concern should be whether your concerns in the first report has been properly addressed by the authors to your satisfaction. It is conventionally regarded (aside from the very high impact journals) as unreasonable to bring up fresh objections that were not in the first report, unless the author’s response brings up a new bombshell. If the revised manuscript is alright then simply note any minor points remaining to be addressed, and leave the rest to the editor. 6.10 Responding effectively to a manuscript peer review Once a painstakingly crafted manuscript has finally been sent off to a journal editor a load may seem lifted from the shoulders of the corresponding author but, of course, the relief is temporary. Perhaps a month or later it will return with a journal response, including detailed and painful critiques from peer reviewers. Here we discuss some ways to cope with this stage. 6.10.1 Opening the letter Other than for short subject review articles it is almost unheard of to get full acceptance with the first review, so read the editorial letter with this in mind. Editors filter manuscripts before sending to peer review and will return a manuscript without review if it is outside the scope of the journal or of insufficient interest to the editor. This type of rejection arrives rapidly (perhaps a couple of weeks), since peer review is not done, and the editor may suggest the manuscript be sent to a sister journal for consideration. However, if the manuscript was peer reviewed, then the editor will apologetically inform the authors that the journal will not accept the manuscript, then will go on to indicate whether the journal will consider an amended manuscript. If they will, then it can be considered a conditional acceptance, so is good news. If not then it is bad news, as it is a rejection and (after taking appropriate account of the rejection criticism) the manuscript must be sent elsewhere. 6.10.2 Rejecting a rejection If authors feel that a rejection is unfair due to (say) a badly misinformed peer review, the authors may consider a letter of appeal to the editor. Such a letter must be short, and demonstrate the flimsiness of the reviewers’ main criticisms, while indicating how the manuscript can be easily improved to counter such criticism. All arguments should be calmly stated (not angry), logical and concise. Aspects to raise include strong supportive evidence from the literature, logical inconsistencies between reviewers on the disputed flaw and whether the journal previously published work with similar apparent issues. Such appeals do not stand usually a good chance of success (it is hard to generalise) but can be worthwhile. 6.10.3 General considerations and the editor perspective Editors are looking for manuscripts that are going to boost the reputation and impact factor of the journal, i.e., papers in the journal are well cited. Manuscripts that are clear and compelling to the editor (and so the journal audience) will be treated well, so they must be well crafted. Correspondence with an editor also needs to respectful and clear. Note that disagreements between reviewers may oblige the editor to go to an additional reviewer, which can take time. 6.10.4 The peer reviews and the types of criticisms (minor, textual, actionable and arguable) Identify reviewer points that are very minor (e.g., a typo) or that can be dealt with by altering the text and deal these immediately. Where a reviewer is very negative about a point it should be addressed in the letter along with corresponding amendments to the text. Where a reviewer objection is raised that requires more work, e.g., undertaking further analysis or adding another study then (if that is feasible and reasonable) it should be done without further ado. Do not simply state that that the work will be done in future studies, especially if it looks easy to do; this is a red rag to an editor. When a reviewer demands something that is arguable or wrong, craft a direct response to this with the help of experienced mentors to try and get the editor onto your side. It can be a good strategy to demonstrate the inanity of a demand to do some pointless work, only then to partly concede (for purposes of goodwill) to add a little extra material. 6.10.5 Framing arguments All discussion of reviewer points must be good natured and scholarly, with an assumption that the reviewer is acting in good faith. Over-politeness and lengthy anguished arguments are of little use where a straight and simple response can be made, as editors are busy. If the reviewer (or editor) is wrong on a point then say so but be prepared to back up the argument with literature references or other argument. The central substance of a reviewer objection should be clearly addressed, and if the objection has merit then concede it and try to repair the manuscript accordingly. If reviewer demands go well beyond the scope of the work, say so and explain why. If the reviewer demands the manuscript work must answer a question it was never intended to address, say so and explain why. If a reviewer demands work that would give open ended answers (i.e., would not provide anything conclusive) say so and explain why. If the reviewers demand is simply unreasonable (e.g., too much difficult work) then say so but be prepared to submit the paper elsewhere if the editor does not agree. Lastly, on rare occasions a reviewer critique is a firehose of strange questions and objections: this may indicate lack of good faith after all. A response may need input from an experienced hand for a letter to the editor raising a possible reviewer conflict of interest. 6.10.6 Dealing with textual changes Manuscript text alterations should be carefully documented in the rebuttal letter and indicated in a copy of the manuscript according to the instructions provided by the journal. 6.10.7 Writing the rebuttal letter The response letter to the editor should be sent within the prescribed period and start with manuscript details (reference number, author, title), then a short and polite summary of how the reviewers concerns have been addressed and how this has made the manuscript stronger. The rebuttal should quote each reviewer point one by one, and under each of these put the author rebuttal or response to that point. This includes details of any text alterations, arguments and additional work done to address the point. If a point raised by reviewer 2 was dealt with in response to reviewer 1 simply indicate this and do not repeat the material. Where text was amended exactly as the reviewer requested, indicate this. Do not constantly thank the reviewers for ‘raising important points’, but equally do not be impolite or caustic. 6.10.8 Substantial alterations and extra work If there is a demand for a lot of extra work to be done, it needs to be considered whether it is better to comply or to withdraw manuscript from review and submit elsewhere. This needs extensive consultation with the co-authors. 6.10.9 Second stage reviews and later Upon returning the manuscript after the first peer review (and rebuttal) the hope is that the editor and reviewers will scan the list of points raised (and responses given), note that all review points have been addressed then then wave it through with only minor quibbles. The tacit contract with the manuscript writer is that if all of the points raised in the first peer review are addressed then the manuscript should be accepted for publication. Points that were not raised in the first response should ideally not be raised later without good reason, especially if further author response to critique is not allowed. After second review the manuscript will again return to the authors, and with luck there will be a request from the editor for the manuscript undergo only minor revision (which may not involve the peer reviewers further) which makes it easy to reach acceptance with the final resubmission. It is not so common to get a rejection after second review but it certainly happens, notably with the very high impact factor journals. With final acceptance the burden is almost lifted but not quite, administrative matters remain, such as bill payments and checking of proofs. However, it is not an unreasonable point to celebrate. "]]
